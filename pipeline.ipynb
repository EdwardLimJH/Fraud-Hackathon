{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read every column except 'device_fraud_count' as its value is a constant 0\n",
    "df = pd.read_csv('Base.csv', usecols=lambda x: x != 'device_fraud_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handle Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with missing values represented by negative values according to documentation\n",
    "missing_features = ['prev_address_months_count', 'current_address_months_count', 'intended_balcon_amount', \n",
    "                    'bank_months_count', 'session_length_in_minutes', 'device_distinct_emails_8w']\n",
    "\n",
    "# Replace negative values with NaN\n",
    "for feature in missing_features:\n",
    "    df[feature] = df[feature].apply(lambda x: x if x >= 0 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop features with a high percentage of missing values, and have very weak correlation with fraud status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['prev_address_months_count', 'intended_balcon_amount', 'bank_months_count']\n",
    "\n",
    "df.drop(features_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with missing values as a very small percentage of the remaining observations have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handle Categorical Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform dummy encoding. Very similar to one-hot encoding, but the first encoded column is dropped to reduce correlation between encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only features with String data type need to be encoded\n",
    "encoded_features = [feature for feature in df.columns if df[feature].dtype == 'object']\n",
    "\n",
    "df = pd.get_dummies(df, columns=encoded_features, drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the feature matrix and target variable\n",
    "X = df.drop('fraud_bool', axis=1)\n",
    "y = df['fraud_bool']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min-Max Scaling (Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From EDA, numerical features were identified. Min-max scaling is applied as parametric models are sensitive to scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['income', 'name_email_similarity', 'current_address_months_count', 'customer_age', 'days_since_request', 'zip_count_4w', 'velocity_6h', 'velocity_24h', \n",
    "                    'velocity_4w', 'bank_branch_count_8w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score', 'proposed_credit_limit', 'session_length_in_minutes']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit only on the training data\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Selection - Backward Stepwise (logistic model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.049074\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 'housing_status_BG' with p-value: 0.9690\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049078\n",
      "         Iterations 10\n",
      "Removing 'device_os_other' with p-value: 0.8933\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049078\n",
      "         Iterations 10\n",
      "Removing 'payment_type_AB' with p-value: 0.8154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049078\n",
      "         Iterations 10\n",
      "Removing 'employment_status_CG' with p-value: 0.7637\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049078\n",
      "         Iterations 10\n",
      "Removing 'payment_type_AE' with p-value: 0.3159\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049079\n",
      "         Iterations 10\n",
      "Removing 'current_address_months_count' with p-value: 0.1137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049081\n",
      "         Iterations 10\n",
      "Removing 'days_since_request' with p-value: 0.1227\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049082\n",
      "         Iterations 10\n",
      "Removing 'payment_type_AD' with p-value: 0.0702\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049084\n",
      "         Iterations 10\n",
      "Selected Features: ['income', 'name_email_similarity', 'customer_age', 'zip_count_4w', 'velocity_6h', 'velocity_24h', 'velocity_4w', 'bank_branch_count_8w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score', 'email_is_free', 'phone_home_valid', 'phone_mobile_valid', 'has_other_cards', 'proposed_credit_limit', 'foreign_request', 'session_length_in_minutes', 'keep_alive_session', 'device_distinct_emails_8w', 'month', 'payment_type_AC', 'employment_status_CB', 'employment_status_CC', 'employment_status_CD', 'employment_status_CE', 'employment_status_CF', 'housing_status_BB', 'housing_status_BC', 'housing_status_BD', 'housing_status_BE', 'housing_status_BF', 'source_TELEAPP', 'device_os_macintosh', 'device_os_windows', 'device_os_x11']\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def backward_stepwise_selection(X, y, p_threshold=0.05):\n",
    "    features = X.columns.tolist()\n",
    "    num_features = len(features)\n",
    "    \n",
    "    for i in range(num_features, 0, -1):\n",
    "        model = sm.Logit(y, X[features]).fit()\n",
    "        p_values = model.pvalues\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value > p_threshold:\n",
    "            remove_feature = p_values.idxmax()\n",
    "            print(f\"Removing '{remove_feature}' with p-value: {max_p_value:.4f}\")\n",
    "            features.remove(remove_feature)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return features\n",
    "\n",
    "selected_features = backward_stepwise_selection(X_train, y_train)\n",
    "print(\"Selected Features:\", selected_features) #35 features\n",
    "#['income', 'name_email_similarity', 'customer_age', 'zip_count_4w', 'velocity_6h', 'velocity_24h', \n",
    "# 'velocity_4w', 'bank_branch_count_8w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score', \n",
    "# 'email_is_free', 'phone_home_valid', 'phone_mobile_valid', 'has_other_cards', 'proposed_credit_limit',\n",
    "# 'foreign_request', 'session_length_in_minutes', 'keep_alive_session', 'device_distinct_emails_8w', 'month',\n",
    "# 'payment_type_AC', 'employment_status_CB', 'employment_status_CC', 'employment_status_CD', 'employment_status_CE',\n",
    "# 'employment_status_CF', 'housing_status_BB', 'housing_status_BC', 'housing_status_BD', 'housing_status_BE', 'housing_status_BF',\n",
    "# 'source_TELEAPP', 'device_os_macintosh', 'device_os_windows', 'device_os_x11']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['income', 'name_email_similarity', 'customer_age', 'zip_count_4w', 'velocity_6h', 'velocity_24h', \n",
    "'velocity_4w', 'bank_branch_count_8w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score', \n",
    "'email_is_free', 'phone_home_valid', 'phone_mobile_valid', 'has_other_cards', 'proposed_credit_limit',\n",
    "'foreign_request', 'session_length_in_minutes', 'keep_alive_session', 'device_distinct_emails_8w', 'month',\n",
    "'payment_type_AC', 'employment_status_CB', 'employment_status_CC', 'employment_status_CD', 'employment_status_CE',\n",
    "'employment_status_CF', 'housing_status_BB', 'housing_status_BC', 'housing_status_BD', 'housing_status_BE', 'housing_status_BF',\n",
    "'source_TELEAPP', 'device_os_macintosh', 'device_os_windows', 'device_os_x11']\n",
    "\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resampling**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraud class vs non fraud class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in y: 98.893%\n",
      "% of fraud class in y: 1.107%\n",
      "\n",
      "% of non-fraud class in y_train: 98.893%\n",
      "% of fraud class in y_train: 1.107%\n",
      "\n",
      "% of non-fraud class in y_test: 98.893%\n",
      "% of fraud class in y_test: 1.107%\n"
     ]
    }
   ],
   "source": [
    "ratio = y.value_counts() / len(y) * 100\n",
    "print(f'% of non-fraud class in y: {round(ratio[0],3)}%\\n% of fraud class in y: {round(ratio[1],3)}%\\n')\n",
    "\n",
    "ratio_train = y_train.value_counts() / len(y_train) * 100\n",
    "print(f'% of non-fraud class in y_train: {round(ratio_train[0],3)}%\\n% of fraud class in y_train: {round(ratio_train[1],3)}%\\n')\n",
    "\n",
    "ratio_test = y_test.value_counts() / len(y_test) * 100\n",
    "print(f'% of non-fraud class in y_test: {round(ratio_test[0],3)}%\\n% of fraud class in y_test: {round(ratio_test[1],3)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in resampled data: 60.024%\n",
      "% of fraud class in resampled data: 39.976%\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42, sampling_strategy = 0.666) #ratio of minority:majority 40:60\n",
    "\n",
    "Xt_resampled_SMOTE, yt_resampled_SMOTE = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "ratio_SMOTE = yt_resampled_SMOTE.value_counts() / len(yt_resampled_SMOTE) * 100\n",
    "print(f'% of non-fraud class in resampled data: {round(ratio_SMOTE[0],3)}%\\n% of fraud class in resampled data: {round(ratio_SMOTE[1],3)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = ['Ratio of Classes', 'Accuracy', 'Recall','Precision', 'F2 Score', 'F1.5 Score','F1 Score', \n",
    "                 'TPR','FNR', \"PR-AUC\", 'Balanced Accuracy', 'Kappa Statistic']\n",
    "results = pd.DataFrame(index= metrics_names,columns=['Original Dataset', 'SMOTE'])\n",
    "class_reports = {}\n",
    "pr_auc_pts = {}\n",
    "\n",
    "results.loc['Ratio of Classes','Original Dataset'] = str(round(ratio_train,3)[0]) + '% : ' +str(round(ratio_train,3)[1])+'%'\n",
    "results.loc['Ratio of Classes','SMOTE'] = str(round(ratio_SMOTE,3)[0]) + '% : ' +str(round(ratio_SMOTE,3)[1])+'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, fbeta_score, f1_score, average_precision_score, precision_recall_curve, confusion_matrix,balanced_accuracy_score, cohen_kappa_score\n",
    "def evaluate_results(model,resampler,x_resampled, y_resampled):\n",
    "\n",
    "    model.fit(x_resampled, y_resampled)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    results.loc['Accuracy',resampler] = accuracy_score(y_test, y_pred_test)\n",
    "    class_reports[resampler] = classification_report(y_test, y_pred_test)\n",
    "    results.loc['Recall',resampler] = recall_score(y_test, y_pred_test)\n",
    "    results.loc['Precision',resampler] = precision_score(y_test, y_pred_test)\n",
    "    results.loc['F2 Score',resampler] = fbeta_score(y_test, y_pred_test, beta =2)\n",
    "    results.loc['F1.5 Score',resampler] = fbeta_score(y_test, y_pred_test, beta =1.5)\n",
    "    results.loc['F1 Score',resampler] = f1_score(y_test, y_pred_test)\n",
    "    results.loc['PR-AUC',resampler] = average_precision_score(y_test, y_pred_test)\n",
    "    pr_auc_pts[resampler] = precision_recall_curve(y_test, y_pred_test)\n",
    "    results.loc['Balanced Accuracy',resampler] = balanced_accuracy_score(y_test, y_pred_test)\n",
    "    results.loc['Kappa Statistic',resampler] = cohen_kappa_score(y_test, y_pred_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred_test, labels=[0,1])\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    TPR = TP/(TP+FN)\n",
    "    FNR = FN/(TP+FN)\n",
    "    results.loc['TPR',resampler] = TPR\n",
    "    results.loc['FNR',resampler] = FNR\n",
    "\n",
    "    print(f\"{resampler} Model Performance on Test Data:\")\n",
    "    print(f\"{resampler} Accuracy:\", results.loc['Accuracy',resampler])\n",
    "    print(f\"{resampler} Precision: {results.loc['Precision',resampler]}\")\n",
    "    print(f\"{resampler} Recall: {results.loc['Recall',resampler]}\")\n",
    "    print(f\"{resampler} F2: {results.loc['F2 Score',resampler]}\")\n",
    "    print(f\"{resampler} F1.5: {results.loc['F1.5 Score',resampler]}\")\n",
    "    print(f\"{resampler} F1: {results.loc['F1 Score',resampler]}\")\n",
    "    print(f\"{resampler} PR-AUC: {results.loc['PR-AUC',resampler]}\")\n",
    "    print(f\"{resampler} TPR: {results.loc['TPR',resampler]}\")\n",
    "    print(f\"{resampler} FNR: {results.loc['FNR',resampler]}\")\n",
    "    print(f\"{resampler} Balanced Accuracy: {results.loc['Balanced Accuracy',resampler]}\")\n",
    "    print(f\"{resampler} Kappa Statistic: {results.loc['Kappa Statistic',resampler]}\")\n",
    "    print(f\"{resampler} Classification Report: \\n{class_reports[resampler]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
