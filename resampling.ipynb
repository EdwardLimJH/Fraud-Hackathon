{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c29284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b0e002e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(\"../Base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "014be961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud_bool                            int64\n",
       "income                              float64\n",
       "name_email_similarity               float64\n",
       "prev_address_months_count             int64\n",
       "current_address_months_count          int64\n",
       "customer_age                          int64\n",
       "days_since_request                  float64\n",
       "intended_balcon_amount              float64\n",
       "payment_type                         object\n",
       "zip_count_4w                          int64\n",
       "velocity_6h                         float64\n",
       "velocity_24h                        float64\n",
       "velocity_4w                         float64\n",
       "bank_branch_count_8w                  int64\n",
       "date_of_birth_distinct_emails_4w      int64\n",
       "employment_status                    object\n",
       "credit_risk_score                     int64\n",
       "email_is_free                         int64\n",
       "housing_status                       object\n",
       "phone_home_valid                      int64\n",
       "phone_mobile_valid                    int64\n",
       "bank_months_count                     int64\n",
       "has_other_cards                       int64\n",
       "proposed_credit_limit               float64\n",
       "foreign_request                       int64\n",
       "source                               object\n",
       "session_length_in_minutes           float64\n",
       "device_os                            object\n",
       "keep_alive_session                    int64\n",
       "device_distinct_emails_8w             int64\n",
       "device_fraud_count                    int64\n",
       "month                                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "48ee956f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AA', 'AD', 'AB', 'AC', 'AE'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base[\"payment_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e3427146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud_bool\n",
       "0    988971\n",
       "1     11029\n",
       "Name: fraud_bool, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.groupby(\"fraud_bool\")[\"fraud_bool\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a02b75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_bool</th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>device_fraud_count</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.986506</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>102.453711</td>\n",
       "      <td>AA</td>\n",
       "      <td>1059</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.224843</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>-1</td>\n",
       "      <td>89</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>-0.849551</td>\n",
       "      <td>AD</td>\n",
       "      <td>1658</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.363854</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.996707</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>-1.490386</td>\n",
       "      <td>AB</td>\n",
       "      <td>1095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>22.730559</td>\n",
       "      <td>windows</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>-1.863101</td>\n",
       "      <td>AB</td>\n",
       "      <td>3483</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>15.215816</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>-1</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>5.742626</td>\n",
       "      <td>47.152498</td>\n",
       "      <td>AA</td>\n",
       "      <td>2339</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.743048</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.124690</td>\n",
       "      <td>-1</td>\n",
       "      <td>143</td>\n",
       "      <td>30</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>-0.826239</td>\n",
       "      <td>AB</td>\n",
       "      <td>530</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.967770</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.824544</td>\n",
       "      <td>-1</td>\n",
       "      <td>193</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>AC</td>\n",
       "      <td>408</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.504109</td>\n",
       "      <td>macintosh</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.140891</td>\n",
       "      <td>-1</td>\n",
       "      <td>202</td>\n",
       "      <td>10</td>\n",
       "      <td>0.059287</td>\n",
       "      <td>50.609995</td>\n",
       "      <td>AA</td>\n",
       "      <td>749</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.068595</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.023357</td>\n",
       "      <td>-1.313387</td>\n",
       "      <td>AB</td>\n",
       "      <td>707</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.378683</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.993391</td>\n",
       "      <td>-1</td>\n",
       "      <td>174</td>\n",
       "      <td>30</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>14.942456</td>\n",
       "      <td>AA</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.947926</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fraud_bool  income  name_email_similarity  prev_address_months_count  \\\n",
       "0                0     0.3               0.986506                         -1   \n",
       "1                0     0.8               0.617426                         -1   \n",
       "2                0     0.8               0.996707                          9   \n",
       "3                0     0.6               0.475100                         11   \n",
       "4                0     0.9               0.842307                         -1   \n",
       "...            ...     ...                    ...                        ...   \n",
       "999995           0     0.8               0.124690                         -1   \n",
       "999996           0     0.9               0.824544                         -1   \n",
       "999997           0     0.8               0.140891                         -1   \n",
       "999998           0     0.9               0.002480                         52   \n",
       "999999           0     0.6               0.993391                         -1   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "0                                 25            40            0.006735   \n",
       "1                                 89            20            0.010095   \n",
       "2                                 14            40            0.012316   \n",
       "3                                 14            30            0.006991   \n",
       "4                                 29            40            5.742626   \n",
       "...                              ...           ...                 ...   \n",
       "999995                           143            30            0.051348   \n",
       "999996                           193            30            0.009591   \n",
       "999997                           202            10            0.059287   \n",
       "999998                             3            30            0.023357   \n",
       "999999                           174            30            0.020422   \n",
       "\n",
       "        intended_balcon_amount payment_type  zip_count_4w  ...  \\\n",
       "0                   102.453711           AA          1059  ...   \n",
       "1                    -0.849551           AD          1658  ...   \n",
       "2                    -1.490386           AB          1095  ...   \n",
       "3                    -1.863101           AB          3483  ...   \n",
       "4                    47.152498           AA          2339  ...   \n",
       "...                        ...          ...           ...  ...   \n",
       "999995               -0.826239           AB           530  ...   \n",
       "999996                0.008307           AC           408  ...   \n",
       "999997               50.609995           AA           749  ...   \n",
       "999998               -1.313387           AB           707  ...   \n",
       "999999               14.942456           AA           655  ...   \n",
       "\n",
       "        has_other_cards  proposed_credit_limit  foreign_request    source  \\\n",
       "0                     0                 1500.0                0  INTERNET   \n",
       "1                     0                 1500.0                0  INTERNET   \n",
       "2                     0                  200.0                0  INTERNET   \n",
       "3                     0                  200.0                0  INTERNET   \n",
       "4                     0                  200.0                0  INTERNET   \n",
       "...                 ...                    ...              ...       ...   \n",
       "999995                0                 1500.0                0  INTERNET   \n",
       "999996                1                 1000.0                0  INTERNET   \n",
       "999997                0                  200.0                0  INTERNET   \n",
       "999998                0                  200.0                0  INTERNET   \n",
       "999999                1                  200.0                0  INTERNET   \n",
       "\n",
       "        session_length_in_minutes  device_os  keep_alive_session  \\\n",
       "0                       16.224843      linux                   1   \n",
       "1                        3.363854      other                   1   \n",
       "2                       22.730559    windows                   0   \n",
       "3                       15.215816      linux                   1   \n",
       "4                        3.743048      other                   0   \n",
       "...                           ...        ...                 ...   \n",
       "999995                  16.967770      other                   0   \n",
       "999996                   1.504109  macintosh                   0   \n",
       "999997                  16.068595      other                   0   \n",
       "999998                   1.378683      linux                   1   \n",
       "999999                   1.947926      other                   1   \n",
       "\n",
       "        device_distinct_emails_8w device_fraud_count  month  \n",
       "0                               1                  0      0  \n",
       "1                               1                  0      0  \n",
       "2                               1                  0      0  \n",
       "3                               1                  0      0  \n",
       "4                               1                  0      0  \n",
       "...                           ...                ...    ...  \n",
       "999995                          1                  0      7  \n",
       "999996                          1                  0      7  \n",
       "999997                          1                  0      7  \n",
       "999998                          1                  0      7  \n",
       "999999                          1                  0      7  \n",
       "\n",
       "[1000000 rows x 32 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261dea0e",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0fec394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base.loc[ : , base.columns != 'fraud_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50f1d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = base[['fraud_bool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "393ffdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 31), (1000000, 1))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fad1e2",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a50bb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23252\\3556639145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[binary_cols] = X[binary_cols].astype(object)\n"
     ]
    }
   ],
   "source": [
    "# categorical columns with numeric dtype (Either binary or month)\n",
    "binary_cols = [ 'email_is_free', 'phone_home_valid', 'phone_mobile_valid','has_other_cards', 'foreign_request','keep_alive_session','month']\n",
    "# change dtype to object\n",
    "X[binary_cols] = X[binary_cols].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef5e4491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>device_fraud_count</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.986506</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>102.453711</td>\n",
       "      <td>AA</td>\n",
       "      <td>1059</td>\n",
       "      <td>13096.035018</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.224843</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>-1</td>\n",
       "      <td>89</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>-0.849551</td>\n",
       "      <td>AD</td>\n",
       "      <td>1658</td>\n",
       "      <td>9223.283431</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.363854</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.996707</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>-1.490386</td>\n",
       "      <td>AB</td>\n",
       "      <td>1095</td>\n",
       "      <td>4471.472149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>22.730559</td>\n",
       "      <td>windows</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>-1.863101</td>\n",
       "      <td>AB</td>\n",
       "      <td>3483</td>\n",
       "      <td>14431.993621</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>15.215816</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>-1</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>5.742626</td>\n",
       "      <td>47.152498</td>\n",
       "      <td>AA</td>\n",
       "      <td>2339</td>\n",
       "      <td>7601.511579</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.743048</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.124690</td>\n",
       "      <td>-1</td>\n",
       "      <td>143</td>\n",
       "      <td>30</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>-0.826239</td>\n",
       "      <td>AB</td>\n",
       "      <td>530</td>\n",
       "      <td>6732.602414</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.967770</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.824544</td>\n",
       "      <td>-1</td>\n",
       "      <td>193</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>AC</td>\n",
       "      <td>408</td>\n",
       "      <td>1574.293294</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.504109</td>\n",
       "      <td>macintosh</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.140891</td>\n",
       "      <td>-1</td>\n",
       "      <td>202</td>\n",
       "      <td>10</td>\n",
       "      <td>0.059287</td>\n",
       "      <td>50.609995</td>\n",
       "      <td>AA</td>\n",
       "      <td>749</td>\n",
       "      <td>1258.864938</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.068595</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.023357</td>\n",
       "      <td>-1.313387</td>\n",
       "      <td>AB</td>\n",
       "      <td>707</td>\n",
       "      <td>7048.137128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.378683</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.993391</td>\n",
       "      <td>-1</td>\n",
       "      <td>174</td>\n",
       "      <td>30</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>14.942456</td>\n",
       "      <td>AA</td>\n",
       "      <td>655</td>\n",
       "      <td>3737.076479</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.947926</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "0          0.3               0.986506                         -1   \n",
       "1          0.8               0.617426                         -1   \n",
       "2          0.8               0.996707                          9   \n",
       "3          0.6               0.475100                         11   \n",
       "4          0.9               0.842307                         -1   \n",
       "...        ...                    ...                        ...   \n",
       "999995     0.8               0.124690                         -1   \n",
       "999996     0.9               0.824544                         -1   \n",
       "999997     0.8               0.140891                         -1   \n",
       "999998     0.9               0.002480                         52   \n",
       "999999     0.6               0.993391                         -1   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "0                                 25            40            0.006735   \n",
       "1                                 89            20            0.010095   \n",
       "2                                 14            40            0.012316   \n",
       "3                                 14            30            0.006991   \n",
       "4                                 29            40            5.742626   \n",
       "...                              ...           ...                 ...   \n",
       "999995                           143            30            0.051348   \n",
       "999996                           193            30            0.009591   \n",
       "999997                           202            10            0.059287   \n",
       "999998                             3            30            0.023357   \n",
       "999999                           174            30            0.020422   \n",
       "\n",
       "        intended_balcon_amount payment_type  zip_count_4w   velocity_6h  ...  \\\n",
       "0                   102.453711           AA          1059  13096.035018  ...   \n",
       "1                    -0.849551           AD          1658   9223.283431  ...   \n",
       "2                    -1.490386           AB          1095   4471.472149  ...   \n",
       "3                    -1.863101           AB          3483  14431.993621  ...   \n",
       "4                    47.152498           AA          2339   7601.511579  ...   \n",
       "...                        ...          ...           ...           ...  ...   \n",
       "999995               -0.826239           AB           530   6732.602414  ...   \n",
       "999996                0.008307           AC           408   1574.293294  ...   \n",
       "999997               50.609995           AA           749   1258.864938  ...   \n",
       "999998               -1.313387           AB           707   7048.137128  ...   \n",
       "999999               14.942456           AA           655   3737.076479  ...   \n",
       "\n",
       "        has_other_cards  proposed_credit_limit  foreign_request    source  \\\n",
       "0                     0                 1500.0                0  INTERNET   \n",
       "1                     0                 1500.0                0  INTERNET   \n",
       "2                     0                  200.0                0  INTERNET   \n",
       "3                     0                  200.0                0  INTERNET   \n",
       "4                     0                  200.0                0  INTERNET   \n",
       "...                 ...                    ...              ...       ...   \n",
       "999995                0                 1500.0                0  INTERNET   \n",
       "999996                1                 1000.0                0  INTERNET   \n",
       "999997                0                  200.0                0  INTERNET   \n",
       "999998                0                  200.0                0  INTERNET   \n",
       "999999                1                  200.0                0  INTERNET   \n",
       "\n",
       "       session_length_in_minutes  device_os keep_alive_session  \\\n",
       "0                      16.224843      linux                  1   \n",
       "1                       3.363854      other                  1   \n",
       "2                      22.730559    windows                  0   \n",
       "3                      15.215816      linux                  1   \n",
       "4                       3.743048      other                  0   \n",
       "...                          ...        ...                ...   \n",
       "999995                 16.967770      other                  0   \n",
       "999996                  1.504109  macintosh                  0   \n",
       "999997                 16.068595      other                  0   \n",
       "999998                  1.378683      linux                  1   \n",
       "999999                  1.947926      other                  1   \n",
       "\n",
       "       device_distinct_emails_8w device_fraud_count month  \n",
       "0                              1                  0     0  \n",
       "1                              1                  0     0  \n",
       "2                              1                  0     0  \n",
       "3                              1                  0     0  \n",
       "4                              1                  0     0  \n",
       "...                          ...                ...   ...  \n",
       "999995                         1                  0     7  \n",
       "999996                         1                  0     7  \n",
       "999997                         1                  0     7  \n",
       "999998                         1                  0     7  \n",
       "999999                         1                  0     7  \n",
       "\n",
       "[1000000 rows x 31 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f13ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X.select_dtypes(include=['int', 'float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c7781f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23252\\114319198.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>device_fraud_count</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.918255</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.157934</td>\n",
       "      <td>0.785651</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.198216</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209790</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>AD</td>\n",
       "      <td>0.247350</td>\n",
       "      <td>0.556307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.050217</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.109273</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.163308</td>\n",
       "      <td>0.274904</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.273082</td>\n",
       "      <td>windows</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.106372</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.519779</td>\n",
       "      <td>0.864767</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.186605</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.073195</td>\n",
       "      <td>0.487853</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.349007</td>\n",
       "      <td>0.460265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.054581</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.124689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335664</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.114442</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.078967</td>\n",
       "      <td>0.408808</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.206766</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452214</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>AC</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.424084</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.028816</td>\n",
       "      <td>macintosh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.140890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.514763</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>0.084653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.427494</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.027373</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407925</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.237167</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.097627</td>\n",
       "      <td>0.231413</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.033924</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "0        0.250               0.986507                   0.000000   \n",
       "1        0.875               0.617426                   0.000000   \n",
       "2        0.875               0.996708                   0.026042   \n",
       "3        0.625               0.475100                   0.031250   \n",
       "4        1.000               0.842307                   0.000000   \n",
       "...        ...                    ...                        ...   \n",
       "999995   0.875               0.124689                   0.000000   \n",
       "999996   1.000               0.824545                   0.000000   \n",
       "999997   0.875               0.140890                   0.000000   \n",
       "999998   1.000               0.002479                   0.138021   \n",
       "999999   0.625               0.993392                   0.000000   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "0                           0.060606         0.375            0.000086   \n",
       "1                           0.209790         0.125            0.000129   \n",
       "2                           0.034965         0.375            0.000157   \n",
       "3                           0.034965         0.250            0.000089   \n",
       "4                           0.069930         0.375            0.073195   \n",
       "...                              ...           ...                 ...   \n",
       "999995                      0.335664         0.250            0.000654   \n",
       "999996                      0.452214         0.250            0.000122   \n",
       "999997                      0.473193         0.000            0.000756   \n",
       "999998                      0.009324         0.250            0.000298   \n",
       "999999                      0.407925         0.250            0.000260   \n",
       "\n",
       "        intended_balcon_amount payment_type  zip_count_4w  velocity_6h  ...  \\\n",
       "0                     0.918255           AA      0.157934     0.785651  ...   \n",
       "1                     0.114260           AD      0.247350     0.556307  ...   \n",
       "2                     0.109273           AB      0.163308     0.274904  ...   \n",
       "3                     0.106372           AB      0.519779     0.864767  ...   \n",
       "4                     0.487853           AA      0.349007     0.460265  ...   \n",
       "...                        ...          ...           ...          ...  ...   \n",
       "999995                0.114442           AB      0.078967     0.408808  ...   \n",
       "999996                0.120937           AC      0.060755     0.103333  ...   \n",
       "999997                0.514763           AA      0.111658     0.084653  ...   \n",
       "999998                0.110650           AB      0.105389     0.427494  ...   \n",
       "999999                0.237167           AA      0.097627     0.231413  ...   \n",
       "\n",
       "        has_other_cards  proposed_credit_limit  foreign_request    source  \\\n",
       "0                     0               0.685864                0  INTERNET   \n",
       "1                     0               0.685864                0  INTERNET   \n",
       "2                     0               0.005236                0  INTERNET   \n",
       "3                     0               0.005236                0  INTERNET   \n",
       "4                     0               0.005236                0  INTERNET   \n",
       "...                 ...                    ...              ...       ...   \n",
       "999995                0               0.685864                0  INTERNET   \n",
       "999996                1               0.424084                0  INTERNET   \n",
       "999997                0               0.005236                0  INTERNET   \n",
       "999998                0               0.005236                0  INTERNET   \n",
       "999999                1               0.005236                0  INTERNET   \n",
       "\n",
       "       session_length_in_minutes  device_os keep_alive_session  \\\n",
       "0                       0.198216      linux                  1   \n",
       "1                       0.050217      other                  1   \n",
       "2                       0.273082    windows                  0   \n",
       "3                       0.186605      linux                  1   \n",
       "4                       0.054581      other                  0   \n",
       "...                          ...        ...                ...   \n",
       "999995                  0.206766      other                  0   \n",
       "999996                  0.028816  macintosh                  0   \n",
       "999997                  0.196418      other                  0   \n",
       "999998                  0.027373      linux                  1   \n",
       "999999                  0.033924      other                  1   \n",
       "\n",
       "       device_distinct_emails_8w device_fraud_count month  \n",
       "0                       0.666667                0.0     0  \n",
       "1                       0.666667                0.0     0  \n",
       "2                       0.666667                0.0     0  \n",
       "3                       0.666667                0.0     0  \n",
       "4                       0.666667                0.0     0  \n",
       "...                          ...                ...   ...  \n",
       "999995                  0.666667                0.0     7  \n",
       "999996                  0.666667                0.0     7  \n",
       "999997                  0.666667                0.0     7  \n",
       "999998                  0.666667                0.0     7  \n",
       "999999                  0.666667                0.0     7  \n",
       "\n",
       "[1000000 rows x 31 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature engineering - scaling\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max Scaling to all numeric columns in X\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "144b6193",
   "metadata": {},
   "source": [
    "### Pearson Correlation - detect mutlicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dfda9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23252\\4142129346.py:5: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlation_matrix = X.corr(method='pearson')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Correlated Features:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Pearson correlation coefficients\n",
    "correlation_matrix = X.corr(method='pearson')\n",
    "\n",
    "# Get the absolute values of the correlation coefficients\n",
    "correlation_matrix_abs = correlation_matrix.abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix (excluding diagonal)\n",
    "upper_triangle = correlation_matrix_abs.where(\n",
    "    np.triu(np.ones(correlation_matrix_abs.shape), k=1).astype(np.bool_))\n",
    "\n",
    "# Find features with correlation greater than a threshold\n",
    "threshold = 0.85  # Example threshold\n",
    "high_correlation_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "\n",
    "# Print highly correlated features\n",
    "print(\"Highly Correlated Features:\")\n",
    "print(high_correlation_features)     #None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413d2ba",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "72996301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>velocity_24h</th>\n",
       "      <th>...</th>\n",
       "      <th>email_is_free</th>\n",
       "      <th>housing_status</th>\n",
       "      <th>phone_home_valid</th>\n",
       "      <th>phone_mobile_valid</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.918255</td>\n",
       "      <td>0.157934</td>\n",
       "      <td>0.785651</td>\n",
       "      <td>0.798218</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209790</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>0.247350</td>\n",
       "      <td>0.556307</td>\n",
       "      <td>0.541631</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.109273</td>\n",
       "      <td>0.163308</td>\n",
       "      <td>0.274904</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>windows</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.106372</td>\n",
       "      <td>0.519779</td>\n",
       "      <td>0.864767</td>\n",
       "      <td>0.664714</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.073195</td>\n",
       "      <td>0.487853</td>\n",
       "      <td>0.349007</td>\n",
       "      <td>0.460265</td>\n",
       "      <td>0.465935</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.124689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335664</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.114442</td>\n",
       "      <td>0.078967</td>\n",
       "      <td>0.408808</td>\n",
       "      <td>0.208338</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BB</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452214</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.172567</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>macintosh</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.140890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.514763</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>0.084653</td>\n",
       "      <td>0.280386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.427494</td>\n",
       "      <td>0.636207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407925</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.237167</td>\n",
       "      <td>0.097627</td>\n",
       "      <td>0.231413</td>\n",
       "      <td>0.223659</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BB</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "0        0.250               0.986507                   0.000000   \n",
       "1        0.875               0.617426                   0.000000   \n",
       "2        0.875               0.996708                   0.026042   \n",
       "3        0.625               0.475100                   0.031250   \n",
       "4        1.000               0.842307                   0.000000   \n",
       "...        ...                    ...                        ...   \n",
       "999995   0.875               0.124689                   0.000000   \n",
       "999996   1.000               0.824545                   0.000000   \n",
       "999997   0.875               0.140890                   0.000000   \n",
       "999998   1.000               0.002479                   0.138021   \n",
       "999999   0.625               0.993392                   0.000000   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "0                           0.060606         0.375            0.000086   \n",
       "1                           0.209790         0.125            0.000129   \n",
       "2                           0.034965         0.375            0.000157   \n",
       "3                           0.034965         0.250            0.000089   \n",
       "4                           0.069930         0.375            0.073195   \n",
       "...                              ...           ...                 ...   \n",
       "999995                      0.335664         0.250            0.000654   \n",
       "999996                      0.452214         0.250            0.000122   \n",
       "999997                      0.473193         0.000            0.000756   \n",
       "999998                      0.009324         0.250            0.000298   \n",
       "999999                      0.407925         0.250            0.000260   \n",
       "\n",
       "        intended_balcon_amount  zip_count_4w  velocity_6h  velocity_24h  ...  \\\n",
       "0                     0.918255      0.157934     0.785651      0.798218  ...   \n",
       "1                     0.114260      0.247350     0.556307      0.541631  ...   \n",
       "2                     0.109273      0.163308     0.274904      0.508333  ...   \n",
       "3                     0.106372      0.519779     0.864767      0.664714  ...   \n",
       "4                     0.487853      0.349007     0.460265      0.465935  ...   \n",
       "...                        ...           ...          ...           ...  ...   \n",
       "999995                0.114442      0.078967     0.408808      0.208338  ...   \n",
       "999996                0.120937      0.060755     0.103333      0.172567  ...   \n",
       "999997                0.514763      0.111658     0.084653      0.280386  ...   \n",
       "999998                0.110650      0.105389     0.427494      0.636207  ...   \n",
       "999999                0.237167      0.097627     0.231413      0.223659  ...   \n",
       "\n",
       "        email_is_free  housing_status  phone_home_valid  phone_mobile_valid  \\\n",
       "0                   1              BC                 0                   1   \n",
       "1                   1              BC                 1                   1   \n",
       "2                   1              BC                 0                   1   \n",
       "3                   1              BC                 0                   1   \n",
       "4                   0              BC                 1                   1   \n",
       "...               ...             ...               ...                 ...   \n",
       "999995              1              BB                 1                   1   \n",
       "999996              0              BA                 1                   1   \n",
       "999997              1              BE                 0                   1   \n",
       "999998              0              BD                 0                   1   \n",
       "999999              1              BB                 0                   1   \n",
       "\n",
       "        has_other_cards  foreign_request    source  device_os  \\\n",
       "0                     0                0  INTERNET      linux   \n",
       "1                     0                0  INTERNET      other   \n",
       "2                     0                0  INTERNET    windows   \n",
       "3                     0                0  INTERNET      linux   \n",
       "4                     0                0  INTERNET      other   \n",
       "...                 ...              ...       ...        ...   \n",
       "999995                0                0  INTERNET      other   \n",
       "999996                1                0  INTERNET  macintosh   \n",
       "999997                0                0  INTERNET      other   \n",
       "999998                0                0  INTERNET      linux   \n",
       "999999                1                0  INTERNET      other   \n",
       "\n",
       "       keep_alive_session month  \n",
       "0                       1     0  \n",
       "1                       1     0  \n",
       "2                       0     0  \n",
       "3                       1     0  \n",
       "4                       0     0  \n",
       "...                   ...   ...  \n",
       "999995                  0     7  \n",
       "999996                  0     7  \n",
       "999997                  0     7  \n",
       "999998                  1     7  \n",
       "999999                  1     7  \n",
       "\n",
       "[1000000 rows x 30 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt = VarianceThreshold(threshold=0.0)\n",
    "\n",
    "# Fit the VarianceThreshold to the selected numeric columns in X\n",
    "vt.fit(X[numeric_cols])\n",
    "\n",
    "# Get the boolean mask of selected numeric features\n",
    "selected_numeric_mask = vt.get_support()\n",
    "\n",
    "# Get the names of the selected numeric features\n",
    "selected_numeric_features = X[numeric_cols].columns[selected_numeric_mask]\n",
    "\n",
    "# Filter X to keep only selected numeric features\n",
    "X_numeric_selected = X[selected_numeric_features]\n",
    "#device_fraud_count is dropped \n",
    "\n",
    "# Get the remaining categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Combine selected numeric features with categorical columns\n",
    "X_selected = pd.concat([X_numeric_selected, X[categorical_cols]], axis=1)\n",
    "X = X_selected\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b75ee7",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69bc0394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Select categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Fit and transform the selected columns with OneHotEncoder\n",
    "encoded_cols = onehot_encoder.fit_transform(X[categorical_cols]).toarray()\n",
    "\n",
    "# Get the feature names for the new one-hot encoded columns\n",
    "# feature_names = onehot_encoder.get_feature_names(categorical_cols)\n",
    "feature_names = onehot_encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Create a DataFrame from the one-hot encoded columns\n",
    "X_encoded = pd.DataFrame(encoded_cols, columns=feature_names)\n",
    "\n",
    "# Replace the original columns with the one-hot encoded columns (optional)\n",
    "X.drop(columns=categorical_cols, inplace=True)\n",
    "X = pd.concat([X, X_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f51dc33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>velocity_24h</th>\n",
       "      <th>...</th>\n",
       "      <th>keep_alive_session_0</th>\n",
       "      <th>keep_alive_session_1</th>\n",
       "      <th>month_0</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.918255</td>\n",
       "      <td>0.157934</td>\n",
       "      <td>0.785651</td>\n",
       "      <td>0.798218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209790</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>0.247350</td>\n",
       "      <td>0.556307</td>\n",
       "      <td>0.541631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.109273</td>\n",
       "      <td>0.163308</td>\n",
       "      <td>0.274904</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.106372</td>\n",
       "      <td>0.519779</td>\n",
       "      <td>0.864767</td>\n",
       "      <td>0.664714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.073195</td>\n",
       "      <td>0.487853</td>\n",
       "      <td>0.349007</td>\n",
       "      <td>0.460265</td>\n",
       "      <td>0.465935</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.124689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335664</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.114442</td>\n",
       "      <td>0.078967</td>\n",
       "      <td>0.408808</td>\n",
       "      <td>0.208338</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452214</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.172567</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.140890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.514763</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>0.084653</td>\n",
       "      <td>0.280386</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.427494</td>\n",
       "      <td>0.636207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407925</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.237167</td>\n",
       "      <td>0.097627</td>\n",
       "      <td>0.231413</td>\n",
       "      <td>0.223659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "0        0.250               0.986507                   0.000000   \n",
       "1        0.875               0.617426                   0.000000   \n",
       "2        0.875               0.996708                   0.026042   \n",
       "3        0.625               0.475100                   0.031250   \n",
       "4        1.000               0.842307                   0.000000   \n",
       "...        ...                    ...                        ...   \n",
       "999995   0.875               0.124689                   0.000000   \n",
       "999996   1.000               0.824545                   0.000000   \n",
       "999997   0.875               0.140890                   0.000000   \n",
       "999998   1.000               0.002479                   0.138021   \n",
       "999999   0.625               0.993392                   0.000000   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "0                           0.060606         0.375            0.000086   \n",
       "1                           0.209790         0.125            0.000129   \n",
       "2                           0.034965         0.375            0.000157   \n",
       "3                           0.034965         0.250            0.000089   \n",
       "4                           0.069930         0.375            0.073195   \n",
       "...                              ...           ...                 ...   \n",
       "999995                      0.335664         0.250            0.000654   \n",
       "999996                      0.452214         0.250            0.000122   \n",
       "999997                      0.473193         0.000            0.000756   \n",
       "999998                      0.009324         0.250            0.000298   \n",
       "999999                      0.407925         0.250            0.000260   \n",
       "\n",
       "        intended_balcon_amount  zip_count_4w  velocity_6h  velocity_24h  ...  \\\n",
       "0                     0.918255      0.157934     0.785651      0.798218  ...   \n",
       "1                     0.114260      0.247350     0.556307      0.541631  ...   \n",
       "2                     0.109273      0.163308     0.274904      0.508333  ...   \n",
       "3                     0.106372      0.519779     0.864767      0.664714  ...   \n",
       "4                     0.487853      0.349007     0.460265      0.465935  ...   \n",
       "...                        ...           ...          ...           ...  ...   \n",
       "999995                0.114442      0.078967     0.408808      0.208338  ...   \n",
       "999996                0.120937      0.060755     0.103333      0.172567  ...   \n",
       "999997                0.514763      0.111658     0.084653      0.280386  ...   \n",
       "999998                0.110650      0.105389     0.427494      0.636207  ...   \n",
       "999999                0.237167      0.097627     0.231413      0.223659  ...   \n",
       "\n",
       "        keep_alive_session_0  keep_alive_session_1  month_0  month_1  month_2  \\\n",
       "0                        0.0                   1.0      1.0      0.0      0.0   \n",
       "1                        0.0                   1.0      1.0      0.0      0.0   \n",
       "2                        1.0                   0.0      1.0      0.0      0.0   \n",
       "3                        0.0                   1.0      1.0      0.0      0.0   \n",
       "4                        1.0                   0.0      1.0      0.0      0.0   \n",
       "...                      ...                   ...      ...      ...      ...   \n",
       "999995                   1.0                   0.0      0.0      0.0      0.0   \n",
       "999996                   1.0                   0.0      0.0      0.0      0.0   \n",
       "999997                   1.0                   0.0      0.0      0.0      0.0   \n",
       "999998                   0.0                   1.0      0.0      0.0      0.0   \n",
       "999999                   0.0                   1.0      0.0      0.0      0.0   \n",
       "\n",
       "        month_3  month_4  month_5  month_6  month_7  \n",
       "0           0.0      0.0      0.0      0.0      0.0  \n",
       "1           0.0      0.0      0.0      0.0      0.0  \n",
       "2           0.0      0.0      0.0      0.0      0.0  \n",
       "3           0.0      0.0      0.0      0.0      0.0  \n",
       "4           0.0      0.0      0.0      0.0      0.0  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "999995      0.0      0.0      0.0      0.0      1.0  \n",
       "999996      0.0      0.0      0.0      0.0      1.0  \n",
       "999997      0.0      0.0      0.0      0.0      1.0  \n",
       "999998      0.0      0.0      0.0      0.0      1.0  \n",
       "999999      0.0      0.0      0.0      0.0      1.0  \n",
       "\n",
       "[1000000 rows x 64 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57eea19",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4645704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import Lasso\n",
    "#import pandas as pd\n",
    "\n",
    "# Initialize the Lasso model with a chosen alpha\n",
    "#lasso = Lasso(alpha=0.001)  # Adjust the alpha value as needed\n",
    "\n",
    "# Fit the Lasso model to the training data\n",
    "#lasso.fit(X_train, y_train)\n",
    "\n",
    "# Get the coefficients and corresponding feature names\n",
    "#feature_names = X_train.columns\n",
    "#lasso_coefficients = pd.DataFrame({'Feature': feature_names, 'Coefficient': lasso.coef_})\n",
    "\n",
    "# Filter the features with non-zero coefficients\n",
    "#selected_features = lasso_coefficients[lasso_coefficients['Coefficient'] != 0]['Feature']\n",
    "#print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d7f5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['income', 'name_email_similarity', 'prev_address_months_count',\n",
      "       'customer_age', 'days_since_request', 'intended_balcon_amount',\n",
      "       'zip_count_4w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score',\n",
      "       'proposed_credit_limit', 'device_distinct_emails_8w', 'payment_type_AA',\n",
      "       'payment_type_AB', 'payment_type_AD', 'payment_type_AE',\n",
      "       'employment_status_CB', 'employment_status_CD', 'employment_status_CE',\n",
      "       'employment_status_CF', 'email_is_free_0', 'email_is_free_1',\n",
      "       'housing_status_BA', 'phone_home_valid_1', 'phone_mobile_valid_0',\n",
      "       'phone_mobile_valid_1', 'has_other_cards_1', 'foreign_request_0',\n",
      "       'foreign_request_1', 'source_INTERNET', 'source_TELEAPP',\n",
      "       'device_os_linux', 'device_os_other', 'device_os_windows',\n",
      "       'keep_alive_session_1', 'month_3'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the estimator (e.g., Logistic Regression)\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "# Initialize RFE with the estimator and number of features to select\n",
    "rfe = RFE(estimator, n_features_to_select=35)  # Adjust number of features as needed\n",
    "\n",
    "# Fit RFE \n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "790ee52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the top 35 features (idk a rough gauge)\n",
    "columns_to_keep = ['income', 'name_email_similarity', 'prev_address_months_count',\n",
    "       'customer_age', 'days_since_request', 'intended_balcon_amount',\n",
    "       'zip_count_4w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score',\n",
    "       'proposed_credit_limit', 'device_distinct_emails_8w', 'payment_type_AA',\n",
    "       'payment_type_AB', 'payment_type_AD', 'payment_type_AE',\n",
    "       'employment_status_CB', 'employment_status_CD', 'employment_status_CE',\n",
    "       'employment_status_CF', 'email_is_free_0', 'email_is_free_1',\n",
    "       'housing_status_BA', 'phone_home_valid_1', 'phone_mobile_valid_0',\n",
    "       'phone_mobile_valid_1', 'has_other_cards_1', 'foreign_request_0',\n",
    "       'foreign_request_1', 'source_INTERNET', 'source_TELEAPP',\n",
    "       'device_os_linux', 'device_os_other', 'device_os_windows',\n",
    "       'keep_alive_session_1', 'month_3']\n",
    "X = X[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a151b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>date_of_birth_distinct_emails_4w</th>\n",
       "      <th>credit_risk_score</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards_1</th>\n",
       "      <th>foreign_request_0</th>\n",
       "      <th>foreign_request_1</th>\n",
       "      <th>source_INTERNET</th>\n",
       "      <th>source_TELEAPP</th>\n",
       "      <th>device_os_linux</th>\n",
       "      <th>device_os_other</th>\n",
       "      <th>device_os_windows</th>\n",
       "      <th>keep_alive_session_1</th>\n",
       "      <th>month_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.918255</td>\n",
       "      <td>0.157934</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.595707</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>0.247350</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.579606</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.109273</td>\n",
       "      <td>0.163308</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.463327</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.106372</td>\n",
       "      <td>0.519779</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.073195</td>\n",
       "      <td>0.487853</td>\n",
       "      <td>0.349007</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.466905</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.124689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.114442</td>\n",
       "      <td>0.078967</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.849732</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.724508</td>\n",
       "      <td>0.424084</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.140890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.514763</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.652952</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.568873</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.237167</td>\n",
       "      <td>0.097627</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.483005</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "0        0.250               0.986507                   0.000000   \n",
       "1        0.875               0.617426                   0.000000   \n",
       "2        0.875               0.996708                   0.026042   \n",
       "3        0.625               0.475100                   0.031250   \n",
       "4        1.000               0.842307                   0.000000   \n",
       "...        ...                    ...                        ...   \n",
       "999995   0.875               0.124689                   0.000000   \n",
       "999996   1.000               0.824545                   0.000000   \n",
       "999997   0.875               0.140890                   0.000000   \n",
       "999998   1.000               0.002479                   0.138021   \n",
       "999999   0.625               0.993392                   0.000000   \n",
       "\n",
       "        customer_age  days_since_request  intended_balcon_amount  \\\n",
       "0              0.375            0.000086                0.918255   \n",
       "1              0.125            0.000129                0.114260   \n",
       "2              0.375            0.000157                0.109273   \n",
       "3              0.250            0.000089                0.106372   \n",
       "4              0.375            0.073195                0.487853   \n",
       "...              ...                 ...                     ...   \n",
       "999995         0.250            0.000654                0.114442   \n",
       "999996         0.250            0.000122                0.120937   \n",
       "999997         0.000            0.000756                0.514763   \n",
       "999998         0.250            0.000298                0.110650   \n",
       "999999         0.250            0.000260                0.237167   \n",
       "\n",
       "        zip_count_4w  date_of_birth_distinct_emails_4w  credit_risk_score  \\\n",
       "0           0.157934                          0.128205           0.595707   \n",
       "1           0.247350                          0.461538           0.579606   \n",
       "2           0.163308                          0.282051           0.463327   \n",
       "3           0.519779                          0.333333           0.465116   \n",
       "4           0.349007                          0.153846           0.466905   \n",
       "...              ...                               ...                ...   \n",
       "999995      0.078967                          0.205128           0.849732   \n",
       "999996      0.060755                          0.128205           0.724508   \n",
       "999997      0.111658                          0.076923           0.652952   \n",
       "999998      0.105389                          0.205128           0.568873   \n",
       "999999      0.097627                          0.205128           0.483005   \n",
       "\n",
       "        proposed_credit_limit  ...  has_other_cards_1  foreign_request_0  \\\n",
       "0                    0.685864  ...                0.0                1.0   \n",
       "1                    0.685864  ...                0.0                1.0   \n",
       "2                    0.005236  ...                0.0                1.0   \n",
       "3                    0.005236  ...                0.0                1.0   \n",
       "4                    0.005236  ...                0.0                1.0   \n",
       "...                       ...  ...                ...                ...   \n",
       "999995               0.685864  ...                0.0                1.0   \n",
       "999996               0.424084  ...                1.0                1.0   \n",
       "999997               0.005236  ...                0.0                1.0   \n",
       "999998               0.005236  ...                0.0                1.0   \n",
       "999999               0.005236  ...                1.0                1.0   \n",
       "\n",
       "        foreign_request_1  source_INTERNET  source_TELEAPP  device_os_linux  \\\n",
       "0                     0.0              1.0             0.0              1.0   \n",
       "1                     0.0              1.0             0.0              0.0   \n",
       "2                     0.0              1.0             0.0              0.0   \n",
       "3                     0.0              1.0             0.0              1.0   \n",
       "4                     0.0              1.0             0.0              0.0   \n",
       "...                   ...              ...             ...              ...   \n",
       "999995                0.0              1.0             0.0              0.0   \n",
       "999996                0.0              1.0             0.0              0.0   \n",
       "999997                0.0              1.0             0.0              0.0   \n",
       "999998                0.0              1.0             0.0              1.0   \n",
       "999999                0.0              1.0             0.0              0.0   \n",
       "\n",
       "        device_os_other  device_os_windows  keep_alive_session_1  month_3  \n",
       "0                   0.0                0.0                   1.0      0.0  \n",
       "1                   1.0                0.0                   1.0      0.0  \n",
       "2                   0.0                1.0                   0.0      0.0  \n",
       "3                   0.0                0.0                   1.0      0.0  \n",
       "4                   1.0                0.0                   0.0      0.0  \n",
       "...                 ...                ...                   ...      ...  \n",
       "999995              1.0                0.0                   0.0      0.0  \n",
       "999996              0.0                0.0                   0.0      0.0  \n",
       "999997              1.0                0.0                   0.0      0.0  \n",
       "999998              0.0                0.0                   1.0      0.0  \n",
       "999999              1.0                0.0                   1.0      0.0  \n",
       "\n",
       "[1000000 rows x 35 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7848ccd3",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eddf8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=109) # 70% training and 30% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4db2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 31)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76682201",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "79578d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in y: 98.897%\n",
      "% of fraud class in y: 1.103%\n",
      "\n",
      "% of non-fraud class in y_train: 98.892%\n",
      "% of fraud class in y_train: 1.108%\n",
      "\n",
      "% of non-fraud class in y_test: 98.909%\n",
      "% of fraud class in y_test: 1.091%\n"
     ]
    }
   ],
   "source": [
    "ratio = y.fraud_bool.value_counts() / len(y) * 100\n",
    "print(f'% of non-fraud class in y: {round(ratio[0],3)}%\\n% of fraud class in y: {round(ratio[1],3)}%\\n')\n",
    "\n",
    "ratio_train = y_train.fraud_bool.value_counts() / len(y_train) * 100\n",
    "print(f'% of non-fraud class in y_train: {round(ratio_train[0],3)}%\\n% of fraud class in y_train: {round(ratio_train[1],3)}%\\n')\n",
    "\n",
    "ratio_test = y_test.fraud_bool.value_counts() / len(y_test) * 100\n",
    "print(f'% of non-fraud class in y_test: {round(ratio_test[0],3)}%\\n% of fraud class in y_test: {round(ratio_test[1],3)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "49a9006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 64 columns):\n",
      " #   Column                            Non-Null Count    Dtype  \n",
      "---  ------                            --------------    -----  \n",
      " 0   income                            1000000 non-null  float64\n",
      " 1   name_email_similarity             1000000 non-null  float64\n",
      " 2   prev_address_months_count         1000000 non-null  float64\n",
      " 3   current_address_months_count      1000000 non-null  float64\n",
      " 4   customer_age                      1000000 non-null  float64\n",
      " 5   days_since_request                1000000 non-null  float64\n",
      " 6   intended_balcon_amount            1000000 non-null  float64\n",
      " 7   zip_count_4w                      1000000 non-null  float64\n",
      " 8   velocity_6h                       1000000 non-null  float64\n",
      " 9   velocity_24h                      1000000 non-null  float64\n",
      " 10  velocity_4w                       1000000 non-null  float64\n",
      " 11  bank_branch_count_8w              1000000 non-null  float64\n",
      " 12  date_of_birth_distinct_emails_4w  1000000 non-null  float64\n",
      " 13  credit_risk_score                 1000000 non-null  float64\n",
      " 14  bank_months_count                 1000000 non-null  float64\n",
      " 15  proposed_credit_limit             1000000 non-null  float64\n",
      " 16  session_length_in_minutes         1000000 non-null  float64\n",
      " 17  device_distinct_emails_8w         1000000 non-null  float64\n",
      " 18  payment_type_AA                   1000000 non-null  float64\n",
      " 19  payment_type_AB                   1000000 non-null  float64\n",
      " 20  payment_type_AC                   1000000 non-null  float64\n",
      " 21  payment_type_AD                   1000000 non-null  float64\n",
      " 22  payment_type_AE                   1000000 non-null  float64\n",
      " 23  employment_status_CA              1000000 non-null  float64\n",
      " 24  employment_status_CB              1000000 non-null  float64\n",
      " 25  employment_status_CC              1000000 non-null  float64\n",
      " 26  employment_status_CD              1000000 non-null  float64\n",
      " 27  employment_status_CE              1000000 non-null  float64\n",
      " 28  employment_status_CF              1000000 non-null  float64\n",
      " 29  employment_status_CG              1000000 non-null  float64\n",
      " 30  email_is_free_0                   1000000 non-null  float64\n",
      " 31  email_is_free_1                   1000000 non-null  float64\n",
      " 32  housing_status_BA                 1000000 non-null  float64\n",
      " 33  housing_status_BB                 1000000 non-null  float64\n",
      " 34  housing_status_BC                 1000000 non-null  float64\n",
      " 35  housing_status_BD                 1000000 non-null  float64\n",
      " 36  housing_status_BE                 1000000 non-null  float64\n",
      " 37  housing_status_BF                 1000000 non-null  float64\n",
      " 38  housing_status_BG                 1000000 non-null  float64\n",
      " 39  phone_home_valid_0                1000000 non-null  float64\n",
      " 40  phone_home_valid_1                1000000 non-null  float64\n",
      " 41  phone_mobile_valid_0              1000000 non-null  float64\n",
      " 42  phone_mobile_valid_1              1000000 non-null  float64\n",
      " 43  has_other_cards_0                 1000000 non-null  float64\n",
      " 44  has_other_cards_1                 1000000 non-null  float64\n",
      " 45  foreign_request_0                 1000000 non-null  float64\n",
      " 46  foreign_request_1                 1000000 non-null  float64\n",
      " 47  source_INTERNET                   1000000 non-null  float64\n",
      " 48  source_TELEAPP                    1000000 non-null  float64\n",
      " 49  device_os_linux                   1000000 non-null  float64\n",
      " 50  device_os_macintosh               1000000 non-null  float64\n",
      " 51  device_os_other                   1000000 non-null  float64\n",
      " 52  device_os_windows                 1000000 non-null  float64\n",
      " 53  device_os_x11                     1000000 non-null  float64\n",
      " 54  keep_alive_session_0              1000000 non-null  float64\n",
      " 55  keep_alive_session_1              1000000 non-null  float64\n",
      " 56  month_0                           1000000 non-null  float64\n",
      " 57  month_1                           1000000 non-null  float64\n",
      " 58  month_2                           1000000 non-null  float64\n",
      " 59  month_3                           1000000 non-null  float64\n",
      " 60  month_4                           1000000 non-null  float64\n",
      " 61  month_5                           1000000 non-null  float64\n",
      " 62  month_6                           1000000 non-null  float64\n",
      " 63  month_7                           1000000 non-null  float64\n",
      "dtypes: float64(64)\n",
      "memory usage: 488.3 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622df4d",
   "metadata": {},
   "source": [
    "### Individual Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170d4bc",
   "metadata": {},
   "source": [
    "#### Random Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fe18a8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in resampled data: 97.832%\n",
      "% of fraud class in resampled data: 2.168%\n",
      "CPU times: total: 531 ms\n",
      "Wall time: 971 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "desired_majority_size = int(0.5 * len(X_train))  # 50% of the original majority class size\n",
    "\n",
    "# Initialize RandomUnderSampler to undersample the majority class to 50%\n",
    "under_sampler = RandomUnderSampler(sampling_strategy={0: desired_majority_size}, random_state=42)\n",
    "\n",
    "# Apply RandomUnderSampler\n",
    "Xt_resampled_under, yt_resampled_under = under_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize SMOTE to oversample the minority class to match the majority class\n",
    "# smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# # Apply SMOTE on the undersampled data\n",
    "# Xt_resampled, yt_resampled = smote.fit_resample(Xt_resampled_under, yt_resampled_under)\n",
    "\n",
    "tmp = yt_resampled_under.fraud_bool.value_counts() / len(yt_resampled_under) * 100\n",
    "print(f'% of non-fraud class in resampled data: {round(tmp[0],3)}%\\n% of fraud class in resampled data: {round(tmp[1],3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe3828",
   "metadata": {},
   "source": [
    "#### Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c4372d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in resampled data: 98.887%\n",
      "% of fraud class in resampled data: 1.113%\n",
      "CPU times: total: 57min 14s\n",
      "Wall time: 25min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "tl = TomekLinks()\n",
    "Xt_resampled_tl, yt_resampled_tl = tl.fit_resample(X_train, y_train)\n",
    "\n",
    "ratio_tl = yt_resampled_tl.fraud_bool.value_counts() / len(yt_resampled_tl) * 100\n",
    "print(f'% of non-fraud class in resampled data: {round(ratio_tl[0],3)}%\\n% of fraud class in resampled data: {round(ratio_tl[1],3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e77e4",
   "metadata": {},
   "source": [
    "#### Cluster Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4cd4f",
   "metadata": {},
   "source": [
    "can tune estimator -- default is KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a1b430a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         y_ = (\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_strategy_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"n_clusters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m                 X_new, y_new = self._generate_sample(\n\u001b[1;32m    192\u001b[0m                     \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;31m# Initialize centers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m             centers_init = self._init_centroids(\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_init_centroids\u001b[0;34m(self, X, x_squared_norms, init, random_state, init_size, n_centroids)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"k-means++\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             centers, _ = _kmeans_plusplus(\n\u001b[0m\u001b[1;32m    953\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_kmeans_plusplus\u001b[0;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Compute distances to center candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         distance_to_candidates = _euclidean_distances(\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcandidate_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_norm_squared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;31m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# from imblearn.under_sampling import ClusterCentroids\n",
    "# cc = ClusterCentroids(random_state = 42)\n",
    "# Xt_resampled_cc, yt_resampled_cc = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "# ratio_cc = yt_resampled_cc.fraud_bool.value_counts() / len(yt_resampled_cc) * 100\n",
    "# print(f'% of non-fraud class in resampled data: {round(ratio_cc[0],3)}%\\n% of fraud class in resampled data: {round(ratio_cc[1],3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340eeb6",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "78071219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in resampled data: 60.024%\n",
      "% of fraud class in resampled data: 39.976%\n",
      "CPU times: total: 2.61 s\n",
      "Wall time: 5.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42, sampling_strategy = 0.666) #ratio of minority:majority 40:60\n",
    "\n",
    "Xt_resampled_SMOTE, yt_resampled_SMOTE = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "ratio_SMOTE = yt_resampled_SMOTE.fraud_bool.value_counts() / len(yt_resampled_SMOTE) * 100\n",
    "print(f'% of non-fraud class in resampled data: {round(ratio_SMOTE[0],3)}%\\n% of fraud class in resampled data: {round(ratio_SMOTE[1],3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc979b9",
   "metadata": {},
   "source": [
    "#### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43218044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in resampled data: 59.939%\n",
      "% of fraud class in resampled data: 40.061%\n",
      "CPU times: total: 41.2 s\n",
      "Wall time: 30 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN(random_state=42, sampling_strategy = 0.666)\n",
    "Xt_resampled_adasyn, yt_resampled_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "ratio_adasyn = yt_resampled_adasyn.fraud_bool.value_counts() / len(yt_resampled_adasyn) * 100\n",
    "print(f'% of non-fraud class in resampled data: {round(ratio_adasyn[0],3)}%\\n% of fraud class in resampled data: {round(ratio_adasyn[1],3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea2872",
   "metadata": {},
   "source": [
    "#### Evaluate Individual Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110e5a1",
   "metadata": {},
   "source": [
    "evaluation metrics to use:\n",
    "1. precision\n",
    "2. recall\n",
    "3. F2, F1.5, F1\n",
    "3. TPR, FNR\n",
    "4. PR-AUC\n",
    "\n",
    "https://sinyi-chou.github.io/python-sklearn-precision-recall/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c45a215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}\n",
    "f2_scores = {}\n",
    "f15_scores = {}\n",
    "f1_scores = {}\n",
    "recall_scores = {}\n",
    "precision_scores = {}\n",
    "class_reports = {}\n",
    "pr_auc = {}\n",
    "pr_auc_pts = {}\n",
    "tpr = {}\n",
    "fnr = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68617fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "logistic = LogisticRegression(random_state=42)\n",
    "# svm = SVC(kernel='linear', random_state=42)\n",
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5aecf387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, fbeta_score, f1_score, average_precision_score, precision_recall_curve, confusion_matrix\n",
    "def evaluate_results(model,resampler,x_resampled, y_resampled):\n",
    "\n",
    "    model.fit(x_resampled, y_resampled)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    accuracies[resampler] = accuracy_score(y_test, y_pred_test)\n",
    "    class_reports[resampler] = classification_report(y_test, y_pred_test)\n",
    "    recall_scores[resampler] = recall_score(y_test, y_pred_test)\n",
    "    precision_scores[resampler] = precision_score(y_test, y_pred_test)\n",
    "    f2_scores[resampler] = fbeta_score(y_test, y_pred_test, beta =2)\n",
    "    f15_scores[resampler] = fbeta_score(y_test, y_pred_test, beta =1.5)\n",
    "    f1_scores[resampler] = f1_score(y_test, y_pred_test)\n",
    "    pr_auc[resampler] = average_precision_score(y_test, y_pred_test)\n",
    "    pr_auc_pts[resampler] = precision_recall_curve(y_test, y_pred_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "    TP = np.diag(cm).astype(float)\n",
    "    FN = (cm.sum(axis=1) -np.diag(cm)).astype(float)\n",
    "    TPR = TP/(TP+FN)\n",
    "    FNR = FN/(TP+FN)\n",
    "    tpr[resampler] = TPR\n",
    "    fnr[resampler] = FNR\n",
    "    # print(cm)\n",
    "    # print(TP,FN)\n",
    "    # print(TPR, FNR)\n",
    "\n",
    "    print(f\"{resampler} Model Performance on Test Data:\")\n",
    "    print(f\"{resampler} Accuracy:\", accuracies[resampler])\n",
    "    print(f\"{resampler} Precision: {precision_scores[resampler]}\")\n",
    "    print(f\"{resampler} Recall: {recall_scores[resampler]}\")\n",
    "    print(f\"{resampler} F2: {f2_scores[resampler]}\")\n",
    "    print(f\"{resampler} F1.5: {f15_scores[resampler]}\")\n",
    "    print(f\"{resampler} F1: {f1_scores[resampler]}\")\n",
    "    print(f\"{resampler} PR-AUC: {pr_auc[resampler]}\")\n",
    "    print(f\"{resampler} Classification Report: \\n{class_reports[resampler]}\")\n",
    "    # print(classification_report(y_test, y_pred_test),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "34a6fc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample Model Performance on Test Data:\n",
      "Random Undersample Accuracy: 0.9888933333333333\n",
      "Random Undersample Precision: 0.4121212121212121\n",
      "Random Undersample Recall: 0.04153940134392181\n",
      "Random Undersample F2: 0.05064799642484731\n",
      "Random Undersample F1.5: 0.05742870135776002\n",
      "Random Undersample F1: 0.07547169811320754\n",
      "Random Undersample PR-AUC: 0.027579268432646565\n",
      "Random Undersample Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.41      0.04      0.08      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.70      0.52      0.53    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links Model Performance on Test Data:\n",
      "Tomek Links Accuracy: 0.98909\n",
      "Tomek Links Precision: 0.5081967213114754\n",
      "Tomek Links Recall: 0.009468540012217471\n",
      "Tomek Links F2: 0.011780801094474424\n",
      "Tomek Links F1.5: 0.013564456411982498\n",
      "Tomek Links F1: 0.018590704647676162\n",
      "Tomek Links PR-AUC: 0.015621880989815439\n",
      "Tomek Links Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.51      0.01      0.02      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.75      0.50      0.51    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Model Performance on Test Data:\n",
      "SMOTE Accuracy: 0.8654733333333333\n",
      "SMOTE Precision: 0.05558218685585543\n",
      "SMOTE Recall: 0.7083078802687843\n",
      "SMOTE F2: 0.21151811448794192\n",
      "SMOTE F1.5: 0.1535339234240199\n",
      "SMOTE F1: 0.10307582896257445\n",
      "SMOTE PR-AUC: 0.04255263428590778\n",
      "SMOTE Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.87    300000\n",
      "   macro avg       0.53      0.79      0.52    300000\n",
      "weighted avg       0.99      0.87      0.92    300000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN Model Performance on Test Data:\n",
      "ADASYN Accuracy: 0.8606966666666667\n",
      "ADASYN Precision: 0.05423234497604333\n",
      "ADASYN Recall: 0.7156383628588882\n",
      "ADASYN F2: 0.20808540116165475\n",
      "ADASYN F1.5: 0.1505798949959956\n",
      "ADASYN F1: 0.10082406351528714\n",
      "ADASYN PR-AUC: 0.04191407990598743\n",
      "ADASYN Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.72      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.92    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_results(logistic,\"Random Undersample\",Xt_resampled_under, yt_resampled_under)\n",
    "evaluate_results(logistic,\"Tomek Links\",Xt_resampled_tl, yt_resampled_tl)\n",
    "#evaluate_results(logistic,\"Cluster Centroid\",Xt_resampled_cc, yt_resampled_cc)\n",
    "evaluate_results(logistic,\"SMOTE\",Xt_resampled_SMOTE, yt_resampled_SMOTE)\n",
    "evaluate_results(logistic,\"ADASYN\",Xt_resampled_adasyn, yt_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699307d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample Model Performance on Test Data:\n",
      "Random Undersample Accuracy: 0.9890866666666667\n",
      "Random Undersample Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.00      0.00      0.00      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.49      0.50      0.50    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links Model Performance on Test Data:\n",
      "Tomek Links Accuracy: 0.9890866666666667\n",
      "Tomek Links Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.00      0.00      0.00      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.49      0.50      0.50    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#evaluate_results(svm,\"Random Undersample\",Xt_resampled_under, yt_resampled_under)\n",
    "#evaluate_results(svm,\"Tomek Links\",Xt_resampled_tl, yt_resampled_tl)\n",
    "#evaluate_results(svm,\"Cluster Centroid\",Xt_resampled_cc, yt_resampled_cc)\n",
    "#evaluate_results(svm,\"SMOTE\",Xt_resampled_SMOTE, yt_resampled_SMOTE)\n",
    "#evaluate_results(svm,\"ADASYN\",Xt_resampled_adasyn, yt_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b2158e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qh/_yq9t4tx45lcx3h89_ggmdm00000gn/T/ipykernel_22624/529661186.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_resampled, y_resampled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample Model Performance on Test Data:\n",
      "Random Undersample Accuracy: 0.9891233333333334\n",
      "Random Undersample Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.54      0.02      0.05      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.76      0.51      0.52    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qh/_yq9t4tx45lcx3h89_ggmdm00000gn/T/ipykernel_22624/529661186.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_resampled, y_resampled)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qh/_yq9t4tx45lcx3h89_ggmdm00000gn/T/ipykernel_22624/149874601.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mevaluate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_classifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Random Undersample\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXt_resampled_under\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt_resampled_under\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_classifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Tomek Links\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXt_resampled_tl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt_resampled_tl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#evaluate_results(rf,\"Cluster Centroid\",Xt_resampled_cc, yt_resampled_cc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_classifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"SMOTE\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXt_resampled_SMOTE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt_resampled_SMOTE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mevaluate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_classifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ADASYN\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXt_resampled_adasyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt_resampled_adasyn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/qh/_yq9t4tx45lcx3h89_ggmdm00000gn/T/ipykernel_22624/529661186.py\u001b[0m in \u001b[0;36mevaluate_results\u001b[0;34m(model, resampler, x_resampled, y_resampled)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    477\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \"\"\"\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    456\u001b[0m             )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluate_results(rf_classifier,\"Random Undersample\",Xt_resampled_under, yt_resampled_under)\n",
    "# evaluate_results(rf_classifier,\"Tomek Links\",Xt_resampled_tl, yt_resampled_tl)\n",
    "# #evaluate_results(rf,\"Cluster Centroid\",Xt_resampled_cc, yt_resampled_cc)\n",
    "# evaluate_results(rf_classifier,\"SMOTE\",Xt_resampled_SMOTE, yt_resampled_SMOTE)\n",
    "# evaluate_results(rf_classifier,\"ADASYN\",Xt_resampled_adasyn, yt_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16f10a",
   "metadata": {},
   "source": [
    "### Combined Undersample + Oversample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae311f5",
   "metadata": {},
   "source": [
    "#### Undersampling methods + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "46d2ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_smote(undersampler, X_undersampled, y_undersampled):\n",
    "    smote = SMOTE(random_state=42, sampling_strategy = 0.666)\n",
    "\n",
    "    # Apply SMOTE on the undersampled data\n",
    "    Xt_resampled, yt_resampled = smote.fit_resample(X_undersampled, y_undersampled)\n",
    "\n",
    "    tmp = yt_resampled.fraud_bool.value_counts() / len(yt_resampled) * 100\n",
    "    print(f'{undersampler}:\\n% of non-fraud class in resampled data: {round(tmp[0],3)}%\\n% of fraud class in resampled data: {round(tmp[1],3)}%')\n",
    "    \n",
    "    evaluate_results(logistic, undersampler+' + SMOTE',Xt_resampled, yt_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "60f95184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample:\n",
      "% of non-fraud class in resampled data: 60.024%\n",
      "% of fraud class in resampled data: 39.976%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample + SMOTE Model Performance on Test Data:\n",
      "Random Undersample + SMOTE Accuracy: 0.8653166666666666\n",
      "Random Undersample + SMOTE Precision: 0.05554092552249168\n",
      "Random Undersample + SMOTE Recall: 0.708613317043372\n",
      "Random Undersample + SMOTE F2: 0.21142034374031748\n",
      "Random Undersample + SMOTE F1.5: 0.15344696006105316\n",
      "Random Undersample + SMOTE F1: 0.10300810300810301\n",
      "Random Undersample + SMOTE PR-AUC: 0.04253703946615171\n",
      "Random Undersample + SMOTE Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.87    300000\n",
      "   macro avg       0.53      0.79      0.52    300000\n",
      "weighted avg       0.99      0.87      0.92    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undersample_smote('Random Undersample',Xt_resampled_under, yt_resampled_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9be01f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links:\n",
      "% of non-fraud class in resampled data: 60.024%\n",
      "% of fraud class in resampled data: 39.976%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links + SMOTE Model Performance on Test Data:\n",
      "Tomek Links + SMOTE Accuracy: 0.8644533333333333\n",
      "Tomek Links + SMOTE Precision: 0.0552198325085649\n",
      "Tomek Links + SMOTE Recall: 0.7089187538179597\n",
      "Tomek Links + SMOTE F2: 0.21051008561892323\n",
      "Tomek Links + SMOTE F1.5: 0.152702005121613\n",
      "Tomek Links + SMOTE F1: 0.10245883547433011\n",
      "Tomek Links + SMOTE PR-AUC: 0.042323041514674954\n",
      "Tomek Links + SMOTE Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.92    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undersample_smote('Tomek Links', Xt_resampled_tl, yt_resampled_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8531a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersample_smote('Cluster Centroid', Xt_resampled_cc, yt_resampled_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ad243",
   "metadata": {},
   "source": [
    "#### Undersampling methods + ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9d0ad409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_adasyn(undersampler, X_undersampled, y_undersampled):\n",
    "    adasyn = ADASYN(random_state=42, sampling_strategy = 0.666)\n",
    "\n",
    "    # Apply SMOTE on the undersampled data\n",
    "    Xt_resampled, yt_resampled = adasyn.fit_resample(X_undersampled, y_undersampled)\n",
    "\n",
    "    tmp = yt_resampled.fraud_bool.value_counts() / len(yt_resampled) * 100\n",
    "    print(f'{undersampler}:\\n% of non-fraud class in resampled data: {round(tmp[0],3)}%\\n% of fraud class in resampled data: {round(tmp[1],3)}%')\n",
    "    \n",
    "    evaluate_results(logistic, undersampler+' + ADASYN',Xt_resampled, yt_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "04e354c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample:\n",
      "% of non-fraud class in resampled data: 59.939%\n",
      "% of fraud class in resampled data: 40.061%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample + ADASYN Model Performance on Test Data:\n",
      "Random Undersample + ADASYN Accuracy: 0.8578966666666666\n",
      "Random Undersample + ADASYN Precision: 0.05370466967545869\n",
      "Random Undersample + ADASYN Recall: 0.7232742822235797\n",
      "Random Undersample + ADASYN F2: 0.2070328209970449\n",
      "Random Undersample + ADASYN F1.5: 0.14955450402743906\n",
      "Random Undersample + ADASYN F1: 0.09998522177887559\n",
      "Random Undersample + ADASYN PR-AUC: 0.04186320641157183\n",
      "Random Undersample + ADASYN Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.72      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.91    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undersample_adasyn('Random Undersample',Xt_resampled_under, yt_resampled_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bd98d9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links:\n",
      "% of non-fraud class in resampled data: 60.084%\n",
      "% of fraud class in resampled data: 39.916%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links + ADASYN Model Performance on Test Data:\n",
      "Tomek Links + ADASYN Accuracy: 0.8595233333333333\n",
      "Tomek Links + ADASYN Precision: 0.05391695549383708\n",
      "Tomek Links + ADASYN Recall: 0.7174709835064141\n",
      "Tomek Links + ADASYN F2: 0.20727811799587031\n",
      "Tomek Links + ADASYN F1.5: 0.1498866168631647\n",
      "Tomek Links + ADASYN F1: 0.10029674857496637\n",
      "Tomek Links + ADASYN PR-AUC: 0.04176718441916818\n",
      "Tomek Links + ADASYN Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.72      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.91    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undersample_adasyn('Tomek Links',Xt_resampled_tl, yt_resampled_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample_adasyn('Cluster Centroid',Xt_resampled_cc, yt_resampled_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3de7ad",
   "metadata": {},
   "source": [
    "### All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "25565bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Undersample</th>\n",
       "      <th>Tomek Links</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>ADASYN</th>\n",
       "      <th>Random Undersample + SMOTE</th>\n",
       "      <th>Tomek Links + SMOTE</th>\n",
       "      <th>Random Undersample + ADASYN</th>\n",
       "      <th>Tomek Links + ADASYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.988893</td>\n",
       "      <td>0.98909</td>\n",
       "      <td>0.865473</td>\n",
       "      <td>0.860697</td>\n",
       "      <td>0.865317</td>\n",
       "      <td>0.864453</td>\n",
       "      <td>0.857897</td>\n",
       "      <td>0.859523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.041539</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.708308</td>\n",
       "      <td>0.715638</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>0.708919</td>\n",
       "      <td>0.723274</td>\n",
       "      <td>0.717471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.412121</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.055582</td>\n",
       "      <td>0.054232</td>\n",
       "      <td>0.055541</td>\n",
       "      <td>0.05522</td>\n",
       "      <td>0.053705</td>\n",
       "      <td>0.053917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2 Score</th>\n",
       "      <td>0.050648</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>0.211518</td>\n",
       "      <td>0.208085</td>\n",
       "      <td>0.21142</td>\n",
       "      <td>0.21051</td>\n",
       "      <td>0.207033</td>\n",
       "      <td>0.207278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1.5 Score</th>\n",
       "      <td>0.057429</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.153534</td>\n",
       "      <td>0.15058</td>\n",
       "      <td>0.153447</td>\n",
       "      <td>0.152702</td>\n",
       "      <td>0.149555</td>\n",
       "      <td>0.149887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.018591</td>\n",
       "      <td>0.103076</td>\n",
       "      <td>0.100824</td>\n",
       "      <td>0.103008</td>\n",
       "      <td>0.102459</td>\n",
       "      <td>0.099985</td>\n",
       "      <td>0.100297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>[0.9993461981760952, 0.04153940134392181]</td>\n",
       "      <td>[0.9998988966251694, 0.009468540012217471]</td>\n",
       "      <td>[0.8672074573849275, 0.7083078802687843]</td>\n",
       "      <td>[0.8622972034806522, 0.7156383628588882]</td>\n",
       "      <td>[0.8670456919851984, 0.708613317043372]</td>\n",
       "      <td>[0.8661694627366662, 0.7089187538179597]</td>\n",
       "      <td>[0.8593820561730351, 0.7232742822235797]</td>\n",
       "      <td>[0.8610907032076731, 0.7174709835064141]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>[0.0006538018239048819, 0.9584605986560782]</td>\n",
       "      <td>[0.00010110337483065185, 0.9905314599877826]</td>\n",
       "      <td>[0.13279254261507248, 0.2916921197312156]</td>\n",
       "      <td>[0.1377027965193478, 0.2843616371411118]</td>\n",
       "      <td>[0.13295430801480154, 0.29138668295662795]</td>\n",
       "      <td>[0.13383053726333385, 0.29108124618204034]</td>\n",
       "      <td>[0.14061794382696494, 0.2767257177764203]</td>\n",
       "      <td>[0.13890929679232694, 0.2825290164935858]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR-AUC</th>\n",
       "      <td>0.027579</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.041914</td>\n",
       "      <td>0.042537</td>\n",
       "      <td>0.042323</td>\n",
       "      <td>0.041863</td>\n",
       "      <td>0.041767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Random Undersample  \\\n",
       "Accuracy                                       0.988893   \n",
       "Recall                                         0.041539   \n",
       "Precision                                      0.412121   \n",
       "F2 Score                                       0.050648   \n",
       "F1.5 Score                                     0.057429   \n",
       "F1 Score                                       0.075472   \n",
       "TPR           [0.9993461981760952, 0.04153940134392181]   \n",
       "FNR         [0.0006538018239048819, 0.9584605986560782]   \n",
       "PR-AUC                                         0.027579   \n",
       "\n",
       "                                             Tomek Links  \\\n",
       "Accuracy                                         0.98909   \n",
       "Recall                                          0.009469   \n",
       "Precision                                       0.508197   \n",
       "F2 Score                                        0.011781   \n",
       "F1.5 Score                                      0.013564   \n",
       "F1 Score                                        0.018591   \n",
       "TPR           [0.9998988966251694, 0.009468540012217471]   \n",
       "FNR         [0.00010110337483065185, 0.9905314599877826]   \n",
       "PR-AUC                                          0.015622   \n",
       "\n",
       "                                                SMOTE  \\\n",
       "Accuracy                                     0.865473   \n",
       "Recall                                       0.708308   \n",
       "Precision                                    0.055582   \n",
       "F2 Score                                     0.211518   \n",
       "F1.5 Score                                   0.153534   \n",
       "F1 Score                                     0.103076   \n",
       "TPR          [0.8672074573849275, 0.7083078802687843]   \n",
       "FNR         [0.13279254261507248, 0.2916921197312156]   \n",
       "PR-AUC                                       0.042553   \n",
       "\n",
       "                                              ADASYN  \\\n",
       "Accuracy                                    0.860697   \n",
       "Recall                                      0.715638   \n",
       "Precision                                   0.054232   \n",
       "F2 Score                                    0.208085   \n",
       "F1.5 Score                                   0.15058   \n",
       "F1 Score                                    0.100824   \n",
       "TPR         [0.8622972034806522, 0.7156383628588882]   \n",
       "FNR         [0.1377027965193478, 0.2843616371411118]   \n",
       "PR-AUC                                      0.041914   \n",
       "\n",
       "                            Random Undersample + SMOTE  \\\n",
       "Accuracy                                      0.865317   \n",
       "Recall                                        0.708613   \n",
       "Precision                                     0.055541   \n",
       "F2 Score                                       0.21142   \n",
       "F1.5 Score                                    0.153447   \n",
       "F1 Score                                      0.103008   \n",
       "TPR            [0.8670456919851984, 0.708613317043372]   \n",
       "FNR         [0.13295430801480154, 0.29138668295662795]   \n",
       "PR-AUC                                        0.042537   \n",
       "\n",
       "                                   Tomek Links + SMOTE  \\\n",
       "Accuracy                                      0.864453   \n",
       "Recall                                        0.708919   \n",
       "Precision                                      0.05522   \n",
       "F2 Score                                       0.21051   \n",
       "F1.5 Score                                    0.152702   \n",
       "F1 Score                                      0.102459   \n",
       "TPR           [0.8661694627366662, 0.7089187538179597]   \n",
       "FNR         [0.13383053726333385, 0.29108124618204034]   \n",
       "PR-AUC                                        0.042323   \n",
       "\n",
       "                          Random Undersample + ADASYN  \\\n",
       "Accuracy                                     0.857897   \n",
       "Recall                                       0.723274   \n",
       "Precision                                    0.053705   \n",
       "F2 Score                                     0.207033   \n",
       "F1.5 Score                                   0.149555   \n",
       "F1 Score                                     0.099985   \n",
       "TPR          [0.8593820561730351, 0.7232742822235797]   \n",
       "FNR         [0.14061794382696494, 0.2767257177764203]   \n",
       "PR-AUC                                       0.041863   \n",
       "\n",
       "                                 Tomek Links + ADASYN  \n",
       "Accuracy                                     0.859523  \n",
       "Recall                                       0.717471  \n",
       "Precision                                    0.053917  \n",
       "F2 Score                                     0.207278  \n",
       "F1.5 Score                                   0.149887  \n",
       "F1 Score                                     0.100297  \n",
       "TPR          [0.8610907032076731, 0.7174709835064141]  \n",
       "FNR         [0.13890929679232694, 0.2825290164935858]  \n",
       "PR-AUC                                       0.041767  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_names = ['Accuracy', 'Recall','Precision', 'F2 Score', 'F1.5 Score','F1 Score', 'TPR','FNR', \"PR-AUC\"]\n",
    "results = pd.DataFrame(index= metrics_names,columns=accuracies.keys())\n",
    "all_results_list = [accuracies, recall_scores, precision_scores, f2_scores,f15_scores,f1_scores, tpr, fnr, pr_auc]\n",
    "for i in range(len(all_results_list)):\n",
    "    for k,v in all_results_list[i].items():\n",
    "        results.loc[metrics_names[i], str(k)] = v\n",
    "        \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "92700102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.41      0.04      0.08      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.70      0.52      0.53    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      " \n",
      "\n",
      "Tomek Links :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.51      0.01      0.02      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.75      0.50      0.51    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      " \n",
      "\n",
      "SMOTE :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.87    300000\n",
      "   macro avg       0.53      0.79      0.52    300000\n",
      "weighted avg       0.99      0.87      0.92    300000\n",
      " \n",
      "\n",
      "ADASYN :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.72      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.92    300000\n",
      " \n",
      "\n",
      "Random Undersample + SMOTE :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.87    300000\n",
      "   macro avg       0.53      0.79      0.52    300000\n",
      "weighted avg       0.99      0.87      0.92    300000\n",
      " \n",
      "\n",
      "Tomek Links + SMOTE :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.92    300000\n",
      " \n",
      "\n",
      "Random Undersample + ADASYN :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.72      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.91    300000\n",
      " \n",
      "\n",
      "Tomek Links + ADASYN :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.72      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.91    300000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in class_reports.items():\n",
    "    print(k,':\\n', v,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "29ff98dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "# iterate over the function list and add a subplot for each function\n",
    "for idx, x in enumerate(pr_auc_pts.items(), start=1):  \n",
    "    resampler = x[0]\n",
    "    v = x[1]\n",
    "    ax = fig.add_subplot(3, 3, idx) # plot with 2 rows and 3 columns\n",
    "    ax.plot(v[0],v[1])\n",
    "    ax.set_title(resampler)\n",
    "    ax.set_ylabel('Recall')\n",
    "    ax.set_xlabel('Precision')\n",
    "    \n",
    "\n",
    "# add spacing between subplots\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
