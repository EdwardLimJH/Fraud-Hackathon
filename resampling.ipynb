{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c29284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e002e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(\"../Base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014be961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud_bool                            int64\n",
       "income                              float64\n",
       "name_email_similarity               float64\n",
       "prev_address_months_count             int64\n",
       "current_address_months_count          int64\n",
       "customer_age                          int64\n",
       "days_since_request                  float64\n",
       "intended_balcon_amount              float64\n",
       "payment_type                         object\n",
       "zip_count_4w                          int64\n",
       "velocity_6h                         float64\n",
       "velocity_24h                        float64\n",
       "velocity_4w                         float64\n",
       "bank_branch_count_8w                  int64\n",
       "date_of_birth_distinct_emails_4w      int64\n",
       "employment_status                    object\n",
       "credit_risk_score                     int64\n",
       "email_is_free                         int64\n",
       "housing_status                       object\n",
       "phone_home_valid                      int64\n",
       "phone_mobile_valid                    int64\n",
       "bank_months_count                     int64\n",
       "has_other_cards                       int64\n",
       "proposed_credit_limit               float64\n",
       "foreign_request                       int64\n",
       "source                               object\n",
       "session_length_in_minutes           float64\n",
       "device_os                            object\n",
       "keep_alive_session                    int64\n",
       "device_distinct_emails_8w             int64\n",
       "device_fraud_count                    int64\n",
       "month                                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ee956f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AA', 'AD', 'AB', 'AC', 'AE'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base[\"payment_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3427146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud_bool\n",
       "0    988971\n",
       "1     11029\n",
       "Name: fraud_bool, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.groupby(\"fraud_bool\")[\"fraud_bool\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a02b75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_bool</th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>device_fraud_count</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.986506</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>102.453711</td>\n",
       "      <td>AA</td>\n",
       "      <td>1059</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.224843</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>-1</td>\n",
       "      <td>89</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>-0.849551</td>\n",
       "      <td>AD</td>\n",
       "      <td>1658</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.363854</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.996707</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>-1.490386</td>\n",
       "      <td>AB</td>\n",
       "      <td>1095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>22.730559</td>\n",
       "      <td>windows</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>-1.863101</td>\n",
       "      <td>AB</td>\n",
       "      <td>3483</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>15.215816</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>-1</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>5.742626</td>\n",
       "      <td>47.152498</td>\n",
       "      <td>AA</td>\n",
       "      <td>2339</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.743048</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.124690</td>\n",
       "      <td>-1</td>\n",
       "      <td>143</td>\n",
       "      <td>30</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>-0.826239</td>\n",
       "      <td>AB</td>\n",
       "      <td>530</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.967770</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.824544</td>\n",
       "      <td>-1</td>\n",
       "      <td>193</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>AC</td>\n",
       "      <td>408</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.504109</td>\n",
       "      <td>macintosh</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.140891</td>\n",
       "      <td>-1</td>\n",
       "      <td>202</td>\n",
       "      <td>10</td>\n",
       "      <td>0.059287</td>\n",
       "      <td>50.609995</td>\n",
       "      <td>AA</td>\n",
       "      <td>749</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.068595</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.023357</td>\n",
       "      <td>-1.313387</td>\n",
       "      <td>AB</td>\n",
       "      <td>707</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.378683</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.993391</td>\n",
       "      <td>-1</td>\n",
       "      <td>174</td>\n",
       "      <td>30</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>14.942456</td>\n",
       "      <td>AA</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.947926</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fraud_bool  income  name_email_similarity  prev_address_months_count  \\\n",
       "0                0     0.3               0.986506                         -1   \n",
       "1                0     0.8               0.617426                         -1   \n",
       "2                0     0.8               0.996707                          9   \n",
       "3                0     0.6               0.475100                         11   \n",
       "4                0     0.9               0.842307                         -1   \n",
       "...            ...     ...                    ...                        ...   \n",
       "999995           0     0.8               0.124690                         -1   \n",
       "999996           0     0.9               0.824544                         -1   \n",
       "999997           0     0.8               0.140891                         -1   \n",
       "999998           0     0.9               0.002480                         52   \n",
       "999999           0     0.6               0.993391                         -1   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "0                                 25            40            0.006735   \n",
       "1                                 89            20            0.010095   \n",
       "2                                 14            40            0.012316   \n",
       "3                                 14            30            0.006991   \n",
       "4                                 29            40            5.742626   \n",
       "...                              ...           ...                 ...   \n",
       "999995                           143            30            0.051348   \n",
       "999996                           193            30            0.009591   \n",
       "999997                           202            10            0.059287   \n",
       "999998                             3            30            0.023357   \n",
       "999999                           174            30            0.020422   \n",
       "\n",
       "        intended_balcon_amount payment_type  zip_count_4w  ...  \\\n",
       "0                   102.453711           AA          1059  ...   \n",
       "1                    -0.849551           AD          1658  ...   \n",
       "2                    -1.490386           AB          1095  ...   \n",
       "3                    -1.863101           AB          3483  ...   \n",
       "4                    47.152498           AA          2339  ...   \n",
       "...                        ...          ...           ...  ...   \n",
       "999995               -0.826239           AB           530  ...   \n",
       "999996                0.008307           AC           408  ...   \n",
       "999997               50.609995           AA           749  ...   \n",
       "999998               -1.313387           AB           707  ...   \n",
       "999999               14.942456           AA           655  ...   \n",
       "\n",
       "        has_other_cards  proposed_credit_limit  foreign_request    source  \\\n",
       "0                     0                 1500.0                0  INTERNET   \n",
       "1                     0                 1500.0                0  INTERNET   \n",
       "2                     0                  200.0                0  INTERNET   \n",
       "3                     0                  200.0                0  INTERNET   \n",
       "4                     0                  200.0                0  INTERNET   \n",
       "...                 ...                    ...              ...       ...   \n",
       "999995                0                 1500.0                0  INTERNET   \n",
       "999996                1                 1000.0                0  INTERNET   \n",
       "999997                0                  200.0                0  INTERNET   \n",
       "999998                0                  200.0                0  INTERNET   \n",
       "999999                1                  200.0                0  INTERNET   \n",
       "\n",
       "        session_length_in_minutes  device_os  keep_alive_session  \\\n",
       "0                       16.224843      linux                   1   \n",
       "1                        3.363854      other                   1   \n",
       "2                       22.730559    windows                   0   \n",
       "3                       15.215816      linux                   1   \n",
       "4                        3.743048      other                   0   \n",
       "...                           ...        ...                 ...   \n",
       "999995                  16.967770      other                   0   \n",
       "999996                   1.504109  macintosh                   0   \n",
       "999997                  16.068595      other                   0   \n",
       "999998                   1.378683      linux                   1   \n",
       "999999                   1.947926      other                   1   \n",
       "\n",
       "        device_distinct_emails_8w device_fraud_count  month  \n",
       "0                               1                  0      0  \n",
       "1                               1                  0      0  \n",
       "2                               1                  0      0  \n",
       "3                               1                  0      0  \n",
       "4                               1                  0      0  \n",
       "...                           ...                ...    ...  \n",
       "999995                          1                  0      7  \n",
       "999996                          1                  0      7  \n",
       "999997                          1                  0      7  \n",
       "999998                          1                  0      7  \n",
       "999999                          1                  0      7  \n",
       "\n",
       "[1000000 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261dea0e",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fec394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base.loc[ : , base.columns != 'fraud_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f1d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = base[['fraud_bool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "393ffdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 31), (1000000, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fad1e2",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a50bb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22572\\3556639145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[binary_cols] = X[binary_cols].astype(object)\n"
     ]
    }
   ],
   "source": [
    "# categorical columns with numeric dtype (Either binary or month)\n",
    "binary_cols = [ 'email_is_free', 'phone_home_valid', 'phone_mobile_valid','has_other_cards', 'foreign_request','keep_alive_session','month']\n",
    "# change dtype to object\n",
    "X[binary_cols] = X[binary_cols].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef5e4491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>device_fraud_count</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.986506</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>102.453711</td>\n",
       "      <td>AA</td>\n",
       "      <td>1059</td>\n",
       "      <td>13096.035018</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.224843</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>-1</td>\n",
       "      <td>89</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>-0.849551</td>\n",
       "      <td>AD</td>\n",
       "      <td>1658</td>\n",
       "      <td>9223.283431</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.363854</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.996707</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>-1.490386</td>\n",
       "      <td>AB</td>\n",
       "      <td>1095</td>\n",
       "      <td>4471.472149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>22.730559</td>\n",
       "      <td>windows</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>-1.863101</td>\n",
       "      <td>AB</td>\n",
       "      <td>3483</td>\n",
       "      <td>14431.993621</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>15.215816</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>-1</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>5.742626</td>\n",
       "      <td>47.152498</td>\n",
       "      <td>AA</td>\n",
       "      <td>2339</td>\n",
       "      <td>7601.511579</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.743048</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.124690</td>\n",
       "      <td>-1</td>\n",
       "      <td>143</td>\n",
       "      <td>30</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>-0.826239</td>\n",
       "      <td>AB</td>\n",
       "      <td>530</td>\n",
       "      <td>6732.602414</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.967770</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.824544</td>\n",
       "      <td>-1</td>\n",
       "      <td>193</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>AC</td>\n",
       "      <td>408</td>\n",
       "      <td>1574.293294</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.504109</td>\n",
       "      <td>macintosh</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.140891</td>\n",
       "      <td>-1</td>\n",
       "      <td>202</td>\n",
       "      <td>10</td>\n",
       "      <td>0.059287</td>\n",
       "      <td>50.609995</td>\n",
       "      <td>AA</td>\n",
       "      <td>749</td>\n",
       "      <td>1258.864938</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>16.068595</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.023357</td>\n",
       "      <td>-1.313387</td>\n",
       "      <td>AB</td>\n",
       "      <td>707</td>\n",
       "      <td>7048.137128</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.378683</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.993391</td>\n",
       "      <td>-1</td>\n",
       "      <td>174</td>\n",
       "      <td>30</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>14.942456</td>\n",
       "      <td>AA</td>\n",
       "      <td>655</td>\n",
       "      <td>3737.076479</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>1.947926</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "0          0.3               0.986506                         -1   \n",
       "1          0.8               0.617426                         -1   \n",
       "2          0.8               0.996707                          9   \n",
       "3          0.6               0.475100                         11   \n",
       "4          0.9               0.842307                         -1   \n",
       "...        ...                    ...                        ...   \n",
       "999995     0.8               0.124690                         -1   \n",
       "999996     0.9               0.824544                         -1   \n",
       "999997     0.8               0.140891                         -1   \n",
       "999998     0.9               0.002480                         52   \n",
       "999999     0.6               0.993391                         -1   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "0                                 25            40            0.006735   \n",
       "1                                 89            20            0.010095   \n",
       "2                                 14            40            0.012316   \n",
       "3                                 14            30            0.006991   \n",
       "4                                 29            40            5.742626   \n",
       "...                              ...           ...                 ...   \n",
       "999995                           143            30            0.051348   \n",
       "999996                           193            30            0.009591   \n",
       "999997                           202            10            0.059287   \n",
       "999998                             3            30            0.023357   \n",
       "999999                           174            30            0.020422   \n",
       "\n",
       "        intended_balcon_amount payment_type  zip_count_4w   velocity_6h  ...  \\\n",
       "0                   102.453711           AA          1059  13096.035018  ...   \n",
       "1                    -0.849551           AD          1658   9223.283431  ...   \n",
       "2                    -1.490386           AB          1095   4471.472149  ...   \n",
       "3                    -1.863101           AB          3483  14431.993621  ...   \n",
       "4                    47.152498           AA          2339   7601.511579  ...   \n",
       "...                        ...          ...           ...           ...  ...   \n",
       "999995               -0.826239           AB           530   6732.602414  ...   \n",
       "999996                0.008307           AC           408   1574.293294  ...   \n",
       "999997               50.609995           AA           749   1258.864938  ...   \n",
       "999998               -1.313387           AB           707   7048.137128  ...   \n",
       "999999               14.942456           AA           655   3737.076479  ...   \n",
       "\n",
       "        has_other_cards  proposed_credit_limit  foreign_request    source  \\\n",
       "0                     0                 1500.0                0  INTERNET   \n",
       "1                     0                 1500.0                0  INTERNET   \n",
       "2                     0                  200.0                0  INTERNET   \n",
       "3                     0                  200.0                0  INTERNET   \n",
       "4                     0                  200.0                0  INTERNET   \n",
       "...                 ...                    ...              ...       ...   \n",
       "999995                0                 1500.0                0  INTERNET   \n",
       "999996                1                 1000.0                0  INTERNET   \n",
       "999997                0                  200.0                0  INTERNET   \n",
       "999998                0                  200.0                0  INTERNET   \n",
       "999999                1                  200.0                0  INTERNET   \n",
       "\n",
       "       session_length_in_minutes  device_os keep_alive_session  \\\n",
       "0                      16.224843      linux                  1   \n",
       "1                       3.363854      other                  1   \n",
       "2                      22.730559    windows                  0   \n",
       "3                      15.215816      linux                  1   \n",
       "4                       3.743048      other                  0   \n",
       "...                          ...        ...                ...   \n",
       "999995                 16.967770      other                  0   \n",
       "999996                  1.504109  macintosh                  0   \n",
       "999997                 16.068595      other                  0   \n",
       "999998                  1.378683      linux                  1   \n",
       "999999                  1.947926      other                  1   \n",
       "\n",
       "       device_distinct_emails_8w device_fraud_count month  \n",
       "0                              1                  0     0  \n",
       "1                              1                  0     0  \n",
       "2                              1                  0     0  \n",
       "3                              1                  0     0  \n",
       "4                              1                  0     0  \n",
       "...                          ...                ...   ...  \n",
       "999995                         1                  0     7  \n",
       "999996                         1                  0     7  \n",
       "999997                         1                  0     7  \n",
       "999998                         1                  0     7  \n",
       "999999                         1                  0     7  \n",
       "\n",
       "[1000000 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f13ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X.select_dtypes(include=['int', 'float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c7781f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22572\\114319198.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>device_fraud_count</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.918255</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.157934</td>\n",
       "      <td>0.785651</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.198216</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209790</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>AD</td>\n",
       "      <td>0.247350</td>\n",
       "      <td>0.556307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.050217</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.109273</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.163308</td>\n",
       "      <td>0.274904</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.273082</td>\n",
       "      <td>windows</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.106372</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.519779</td>\n",
       "      <td>0.864767</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.186605</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.073195</td>\n",
       "      <td>0.487853</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.349007</td>\n",
       "      <td>0.460265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.054581</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.124689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335664</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.114442</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.078967</td>\n",
       "      <td>0.408808</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.206766</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452214</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>AC</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.424084</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.028816</td>\n",
       "      <td>macintosh</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.140890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.514763</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>0.084653</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.427494</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.027373</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407925</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.237167</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.097627</td>\n",
       "      <td>0.231413</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.033924</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "0        0.250               0.986507                   0.000000   \n",
       "1        0.875               0.617426                   0.000000   \n",
       "2        0.875               0.996708                   0.026042   \n",
       "3        0.625               0.475100                   0.031250   \n",
       "4        1.000               0.842307                   0.000000   \n",
       "...        ...                    ...                        ...   \n",
       "999995   0.875               0.124689                   0.000000   \n",
       "999996   1.000               0.824545                   0.000000   \n",
       "999997   0.875               0.140890                   0.000000   \n",
       "999998   1.000               0.002479                   0.138021   \n",
       "999999   0.625               0.993392                   0.000000   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "0                           0.060606         0.375            0.000086   \n",
       "1                           0.209790         0.125            0.000129   \n",
       "2                           0.034965         0.375            0.000157   \n",
       "3                           0.034965         0.250            0.000089   \n",
       "4                           0.069930         0.375            0.073195   \n",
       "...                              ...           ...                 ...   \n",
       "999995                      0.335664         0.250            0.000654   \n",
       "999996                      0.452214         0.250            0.000122   \n",
       "999997                      0.473193         0.000            0.000756   \n",
       "999998                      0.009324         0.250            0.000298   \n",
       "999999                      0.407925         0.250            0.000260   \n",
       "\n",
       "        intended_balcon_amount payment_type  zip_count_4w  velocity_6h  ...  \\\n",
       "0                     0.918255           AA      0.157934     0.785651  ...   \n",
       "1                     0.114260           AD      0.247350     0.556307  ...   \n",
       "2                     0.109273           AB      0.163308     0.274904  ...   \n",
       "3                     0.106372           AB      0.519779     0.864767  ...   \n",
       "4                     0.487853           AA      0.349007     0.460265  ...   \n",
       "...                        ...          ...           ...          ...  ...   \n",
       "999995                0.114442           AB      0.078967     0.408808  ...   \n",
       "999996                0.120937           AC      0.060755     0.103333  ...   \n",
       "999997                0.514763           AA      0.111658     0.084653  ...   \n",
       "999998                0.110650           AB      0.105389     0.427494  ...   \n",
       "999999                0.237167           AA      0.097627     0.231413  ...   \n",
       "\n",
       "        has_other_cards  proposed_credit_limit  foreign_request    source  \\\n",
       "0                     0               0.685864                0  INTERNET   \n",
       "1                     0               0.685864                0  INTERNET   \n",
       "2                     0               0.005236                0  INTERNET   \n",
       "3                     0               0.005236                0  INTERNET   \n",
       "4                     0               0.005236                0  INTERNET   \n",
       "...                 ...                    ...              ...       ...   \n",
       "999995                0               0.685864                0  INTERNET   \n",
       "999996                1               0.424084                0  INTERNET   \n",
       "999997                0               0.005236                0  INTERNET   \n",
       "999998                0               0.005236                0  INTERNET   \n",
       "999999                1               0.005236                0  INTERNET   \n",
       "\n",
       "       session_length_in_minutes  device_os keep_alive_session  \\\n",
       "0                       0.198216      linux                  1   \n",
       "1                       0.050217      other                  1   \n",
       "2                       0.273082    windows                  0   \n",
       "3                       0.186605      linux                  1   \n",
       "4                       0.054581      other                  0   \n",
       "...                          ...        ...                ...   \n",
       "999995                  0.206766      other                  0   \n",
       "999996                  0.028816  macintosh                  0   \n",
       "999997                  0.196418      other                  0   \n",
       "999998                  0.027373      linux                  1   \n",
       "999999                  0.033924      other                  1   \n",
       "\n",
       "       device_distinct_emails_8w device_fraud_count month  \n",
       "0                       0.666667                0.0     0  \n",
       "1                       0.666667                0.0     0  \n",
       "2                       0.666667                0.0     0  \n",
       "3                       0.666667                0.0     0  \n",
       "4                       0.666667                0.0     0  \n",
       "...                          ...                ...   ...  \n",
       "999995                  0.666667                0.0     7  \n",
       "999996                  0.666667                0.0     7  \n",
       "999997                  0.666667                0.0     7  \n",
       "999998                  0.666667                0.0     7  \n",
       "999999                  0.666667                0.0     7  \n",
       "\n",
       "[1000000 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature engineering - scaling\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max Scaling to all numeric columns in X\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "144b6193",
   "metadata": {},
   "source": [
    "### Pearson Correlation - detect mutlicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfda9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22572\\4142129346.py:5: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlation_matrix = X.corr(method='pearson')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Correlated Features:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Pearson correlation coefficients\n",
    "correlation_matrix = X.corr(method='pearson')\n",
    "\n",
    "# Get the absolute values of the correlation coefficients\n",
    "correlation_matrix_abs = correlation_matrix.abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix (excluding diagonal)\n",
    "upper_triangle = correlation_matrix_abs.where(\n",
    "    np.triu(np.ones(correlation_matrix_abs.shape), k=1).astype(np.bool_))\n",
    "\n",
    "# Find features with correlation greater than a threshold\n",
    "threshold = 0.85  # Example threshold\n",
    "high_correlation_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "\n",
    "# Print highly correlated features\n",
    "print(\"Highly Correlated Features:\")\n",
    "print(high_correlation_features)     #None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413d2ba",
   "metadata": {},
   "source": [
    "### Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72996301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>velocity_24h</th>\n",
       "      <th>...</th>\n",
       "      <th>email_is_free</th>\n",
       "      <th>housing_status</th>\n",
       "      <th>phone_home_valid</th>\n",
       "      <th>phone_mobile_valid</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.918255</td>\n",
       "      <td>0.157934</td>\n",
       "      <td>0.785651</td>\n",
       "      <td>0.798218</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209790</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>0.247350</td>\n",
       "      <td>0.556307</td>\n",
       "      <td>0.541631</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.109273</td>\n",
       "      <td>0.163308</td>\n",
       "      <td>0.274904</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>windows</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.106372</td>\n",
       "      <td>0.519779</td>\n",
       "      <td>0.864767</td>\n",
       "      <td>0.664714</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.073195</td>\n",
       "      <td>0.487853</td>\n",
       "      <td>0.349007</td>\n",
       "      <td>0.460265</td>\n",
       "      <td>0.465935</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.124689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335664</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.114442</td>\n",
       "      <td>0.078967</td>\n",
       "      <td>0.408808</td>\n",
       "      <td>0.208338</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BB</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452214</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.172567</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>macintosh</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.140890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.514763</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>0.084653</td>\n",
       "      <td>0.280386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.427494</td>\n",
       "      <td>0.636207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>linux</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407925</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.237167</td>\n",
       "      <td>0.097627</td>\n",
       "      <td>0.231413</td>\n",
       "      <td>0.223659</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>BB</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "0        0.250               0.986507                   0.000000   \n",
       "1        0.875               0.617426                   0.000000   \n",
       "2        0.875               0.996708                   0.026042   \n",
       "3        0.625               0.475100                   0.031250   \n",
       "4        1.000               0.842307                   0.000000   \n",
       "...        ...                    ...                        ...   \n",
       "999995   0.875               0.124689                   0.000000   \n",
       "999996   1.000               0.824545                   0.000000   \n",
       "999997   0.875               0.140890                   0.000000   \n",
       "999998   1.000               0.002479                   0.138021   \n",
       "999999   0.625               0.993392                   0.000000   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "0                           0.060606         0.375            0.000086   \n",
       "1                           0.209790         0.125            0.000129   \n",
       "2                           0.034965         0.375            0.000157   \n",
       "3                           0.034965         0.250            0.000089   \n",
       "4                           0.069930         0.375            0.073195   \n",
       "...                              ...           ...                 ...   \n",
       "999995                      0.335664         0.250            0.000654   \n",
       "999996                      0.452214         0.250            0.000122   \n",
       "999997                      0.473193         0.000            0.000756   \n",
       "999998                      0.009324         0.250            0.000298   \n",
       "999999                      0.407925         0.250            0.000260   \n",
       "\n",
       "        intended_balcon_amount  zip_count_4w  velocity_6h  velocity_24h  ...  \\\n",
       "0                     0.918255      0.157934     0.785651      0.798218  ...   \n",
       "1                     0.114260      0.247350     0.556307      0.541631  ...   \n",
       "2                     0.109273      0.163308     0.274904      0.508333  ...   \n",
       "3                     0.106372      0.519779     0.864767      0.664714  ...   \n",
       "4                     0.487853      0.349007     0.460265      0.465935  ...   \n",
       "...                        ...           ...          ...           ...  ...   \n",
       "999995                0.114442      0.078967     0.408808      0.208338  ...   \n",
       "999996                0.120937      0.060755     0.103333      0.172567  ...   \n",
       "999997                0.514763      0.111658     0.084653      0.280386  ...   \n",
       "999998                0.110650      0.105389     0.427494      0.636207  ...   \n",
       "999999                0.237167      0.097627     0.231413      0.223659  ...   \n",
       "\n",
       "        email_is_free  housing_status  phone_home_valid  phone_mobile_valid  \\\n",
       "0                   1              BC                 0                   1   \n",
       "1                   1              BC                 1                   1   \n",
       "2                   1              BC                 0                   1   \n",
       "3                   1              BC                 0                   1   \n",
       "4                   0              BC                 1                   1   \n",
       "...               ...             ...               ...                 ...   \n",
       "999995              1              BB                 1                   1   \n",
       "999996              0              BA                 1                   1   \n",
       "999997              1              BE                 0                   1   \n",
       "999998              0              BD                 0                   1   \n",
       "999999              1              BB                 0                   1   \n",
       "\n",
       "        has_other_cards  foreign_request    source  device_os  \\\n",
       "0                     0                0  INTERNET      linux   \n",
       "1                     0                0  INTERNET      other   \n",
       "2                     0                0  INTERNET    windows   \n",
       "3                     0                0  INTERNET      linux   \n",
       "4                     0                0  INTERNET      other   \n",
       "...                 ...              ...       ...        ...   \n",
       "999995                0                0  INTERNET      other   \n",
       "999996                1                0  INTERNET  macintosh   \n",
       "999997                0                0  INTERNET      other   \n",
       "999998                0                0  INTERNET      linux   \n",
       "999999                1                0  INTERNET      other   \n",
       "\n",
       "       keep_alive_session month  \n",
       "0                       1     0  \n",
       "1                       1     0  \n",
       "2                       0     0  \n",
       "3                       1     0  \n",
       "4                       0     0  \n",
       "...                   ...   ...  \n",
       "999995                  0     7  \n",
       "999996                  0     7  \n",
       "999997                  0     7  \n",
       "999998                  1     7  \n",
       "999999                  1     7  \n",
       "\n",
       "[1000000 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt = VarianceThreshold(threshold=0.0)\n",
    "\n",
    "# Fit the VarianceThreshold to the selected numeric columns in X\n",
    "vt.fit(X[numeric_cols])\n",
    "\n",
    "# Get the boolean mask of selected numeric features\n",
    "selected_numeric_mask = vt.get_support()\n",
    "\n",
    "# Get the names of the selected numeric features\n",
    "selected_numeric_features = X[numeric_cols].columns[selected_numeric_mask]\n",
    "\n",
    "# Filter X to keep only selected numeric features\n",
    "X_numeric_selected = X[selected_numeric_features]\n",
    "#device_fraud_count is dropped \n",
    "\n",
    "# Get the remaining categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Combine selected numeric features with categorical columns\n",
    "X_selected = pd.concat([X_numeric_selected, X[categorical_cols]], axis=1)\n",
    "X = X_selected\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b75ee7",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69bc0394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Select categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Fit and transform the selected columns with OneHotEncoder\n",
    "encoded_cols = onehot_encoder.fit_transform(X[categorical_cols]).toarray()\n",
    "\n",
    "# Get the feature names for the new one-hot encoded columns\n",
    "# feature_names = onehot_encoder.get_feature_names(categorical_cols)\n",
    "feature_names = onehot_encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Create a DataFrame from the one-hot encoded columns\n",
    "X_encoded = pd.DataFrame(encoded_cols, columns=feature_names)\n",
    "\n",
    "# Replace the original columns with the one-hot encoded columns (optional)\n",
    "X.drop(columns=categorical_cols, inplace=True)\n",
    "X = pd.concat([X, X_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f51dc33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>velocity_24h</th>\n",
       "      <th>...</th>\n",
       "      <th>keep_alive_session_0</th>\n",
       "      <th>keep_alive_session_1</th>\n",
       "      <th>month_0</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.918255</td>\n",
       "      <td>0.157934</td>\n",
       "      <td>0.785651</td>\n",
       "      <td>0.798218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209790</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>0.247350</td>\n",
       "      <td>0.556307</td>\n",
       "      <td>0.541631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.109273</td>\n",
       "      <td>0.163308</td>\n",
       "      <td>0.274904</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.106372</td>\n",
       "      <td>0.519779</td>\n",
       "      <td>0.864767</td>\n",
       "      <td>0.664714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.073195</td>\n",
       "      <td>0.487853</td>\n",
       "      <td>0.349007</td>\n",
       "      <td>0.460265</td>\n",
       "      <td>0.465935</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.124689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335664</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.114442</td>\n",
       "      <td>0.078967</td>\n",
       "      <td>0.408808</td>\n",
       "      <td>0.208338</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452214</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.172567</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.140890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.514763</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>0.084653</td>\n",
       "      <td>0.280386</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.009324</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.427494</td>\n",
       "      <td>0.636207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407925</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.237167</td>\n",
       "      <td>0.097627</td>\n",
       "      <td>0.231413</td>\n",
       "      <td>0.223659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "0        0.250               0.986507                   0.000000   \n",
       "1        0.875               0.617426                   0.000000   \n",
       "2        0.875               0.996708                   0.026042   \n",
       "3        0.625               0.475100                   0.031250   \n",
       "4        1.000               0.842307                   0.000000   \n",
       "...        ...                    ...                        ...   \n",
       "999995   0.875               0.124689                   0.000000   \n",
       "999996   1.000               0.824545                   0.000000   \n",
       "999997   0.875               0.140890                   0.000000   \n",
       "999998   1.000               0.002479                   0.138021   \n",
       "999999   0.625               0.993392                   0.000000   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "0                           0.060606         0.375            0.000086   \n",
       "1                           0.209790         0.125            0.000129   \n",
       "2                           0.034965         0.375            0.000157   \n",
       "3                           0.034965         0.250            0.000089   \n",
       "4                           0.069930         0.375            0.073195   \n",
       "...                              ...           ...                 ...   \n",
       "999995                      0.335664         0.250            0.000654   \n",
       "999996                      0.452214         0.250            0.000122   \n",
       "999997                      0.473193         0.000            0.000756   \n",
       "999998                      0.009324         0.250            0.000298   \n",
       "999999                      0.407925         0.250            0.000260   \n",
       "\n",
       "        intended_balcon_amount  zip_count_4w  velocity_6h  velocity_24h  ...  \\\n",
       "0                     0.918255      0.157934     0.785651      0.798218  ...   \n",
       "1                     0.114260      0.247350     0.556307      0.541631  ...   \n",
       "2                     0.109273      0.163308     0.274904      0.508333  ...   \n",
       "3                     0.106372      0.519779     0.864767      0.664714  ...   \n",
       "4                     0.487853      0.349007     0.460265      0.465935  ...   \n",
       "...                        ...           ...          ...           ...  ...   \n",
       "999995                0.114442      0.078967     0.408808      0.208338  ...   \n",
       "999996                0.120937      0.060755     0.103333      0.172567  ...   \n",
       "999997                0.514763      0.111658     0.084653      0.280386  ...   \n",
       "999998                0.110650      0.105389     0.427494      0.636207  ...   \n",
       "999999                0.237167      0.097627     0.231413      0.223659  ...   \n",
       "\n",
       "        keep_alive_session_0  keep_alive_session_1  month_0  month_1  month_2  \\\n",
       "0                        0.0                   1.0      1.0      0.0      0.0   \n",
       "1                        0.0                   1.0      1.0      0.0      0.0   \n",
       "2                        1.0                   0.0      1.0      0.0      0.0   \n",
       "3                        0.0                   1.0      1.0      0.0      0.0   \n",
       "4                        1.0                   0.0      1.0      0.0      0.0   \n",
       "...                      ...                   ...      ...      ...      ...   \n",
       "999995                   1.0                   0.0      0.0      0.0      0.0   \n",
       "999996                   1.0                   0.0      0.0      0.0      0.0   \n",
       "999997                   1.0                   0.0      0.0      0.0      0.0   \n",
       "999998                   0.0                   1.0      0.0      0.0      0.0   \n",
       "999999                   0.0                   1.0      0.0      0.0      0.0   \n",
       "\n",
       "        month_3  month_4  month_5  month_6  month_7  \n",
       "0           0.0      0.0      0.0      0.0      0.0  \n",
       "1           0.0      0.0      0.0      0.0      0.0  \n",
       "2           0.0      0.0      0.0      0.0      0.0  \n",
       "3           0.0      0.0      0.0      0.0      0.0  \n",
       "4           0.0      0.0      0.0      0.0      0.0  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "999995      0.0      0.0      0.0      0.0      1.0  \n",
       "999996      0.0      0.0      0.0      0.0      1.0  \n",
       "999997      0.0      0.0      0.0      0.0      1.0  \n",
       "999998      0.0      0.0      0.0      0.0      1.0  \n",
       "999999      0.0      0.0      0.0      0.0      1.0  \n",
       "\n",
       "[1000000 rows x 64 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57eea19",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4645704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import Lasso\n",
    "#import pandas as pd\n",
    "\n",
    "# Initialize the Lasso model with a chosen alpha\n",
    "#lasso = Lasso(alpha=0.001)  # Adjust the alpha value as needed\n",
    "\n",
    "# Fit the Lasso model to the training data\n",
    "#lasso.fit(X_train, y_train)\n",
    "\n",
    "# Get the coefficients and corresponding feature names\n",
    "#feature_names = X_train.columns\n",
    "#lasso_coefficients = pd.DataFrame({'Feature': feature_names, 'Coefficient': lasso.coef_})\n",
    "\n",
    "# Filter the features with non-zero coefficients\n",
    "#selected_features = lasso_coefficients[lasso_coefficients['Coefficient'] != 0]['Feature']\n",
    "#print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bdac8f",
   "metadata": {},
   "source": [
    "#### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d7f5abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['income', 'name_email_similarity', 'prev_address_months_count',\n",
      "       'customer_age', 'days_since_request', 'intended_balcon_amount',\n",
      "       'zip_count_4w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score',\n",
      "       'proposed_credit_limit', 'device_distinct_emails_8w', 'payment_type_AA',\n",
      "       'payment_type_AB', 'payment_type_AD', 'payment_type_AE',\n",
      "       'employment_status_CB', 'employment_status_CD', 'employment_status_CE',\n",
      "       'employment_status_CF', 'email_is_free_0', 'email_is_free_1',\n",
      "       'housing_status_BA', 'phone_home_valid_1', 'phone_mobile_valid_0',\n",
      "       'phone_mobile_valid_1', 'has_other_cards_1', 'foreign_request_0',\n",
      "       'foreign_request_1', 'source_INTERNET', 'source_TELEAPP',\n",
      "       'device_os_linux', 'device_os_other', 'device_os_windows',\n",
      "       'keep_alive_session_1', 'month_3'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanshereen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the estimator (e.g., Logistic Regression)\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "# Initialize RFE with the estimator and number of features to select\n",
    "rfe = RFE(estimator, n_features_to_select=35)  # Adjust number of features as needed\n",
    "\n",
    "# Fit RFE \n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "790ee52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #the top 35 features (idk a rough gauge)\n",
    "# columns_to_keep = ['income', 'name_email_similarity', 'prev_address_months_count',\n",
    "#        'customer_age', 'days_since_request', 'intended_balcon_amount',\n",
    "#        'zip_count_4w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score',\n",
    "#        'proposed_credit_limit', 'device_distinct_emails_8w', 'payment_type_AA',\n",
    "#        'payment_type_AB', 'payment_type_AD', 'payment_type_AE',\n",
    "#        'employment_status_CB', 'employment_status_CD', 'employment_status_CE',\n",
    "#        'employment_status_CF', 'email_is_free_0', 'email_is_free_1',\n",
    "#        'housing_status_BA', 'phone_home_valid_1', 'phone_mobile_valid_0',\n",
    "#        'phone_mobile_valid_1', 'has_other_cards_1', 'foreign_request_0',\n",
    "#        'foreign_request_1', 'source_INTERNET', 'source_TELEAPP',\n",
    "#        'device_os_linux', 'device_os_other', 'device_os_windows',\n",
    "#        'keep_alive_session_1', 'month_3']\n",
    "# X = X[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a151b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>date_of_birth_distinct_emails_4w</th>\n",
       "      <th>credit_risk_score</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards_1</th>\n",
       "      <th>foreign_request_0</th>\n",
       "      <th>foreign_request_1</th>\n",
       "      <th>source_INTERNET</th>\n",
       "      <th>source_TELEAPP</th>\n",
       "      <th>device_os_linux</th>\n",
       "      <th>device_os_other</th>\n",
       "      <th>device_os_windows</th>\n",
       "      <th>keep_alive_session_1</th>\n",
       "      <th>month_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.918255</td>\n",
       "      <td>0.157934</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.595707</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.617426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.114260</td>\n",
       "      <td>0.247350</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.579606</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.109273</td>\n",
       "      <td>0.163308</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.463327</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.106372</td>\n",
       "      <td>0.519779</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.073195</td>\n",
       "      <td>0.487853</td>\n",
       "      <td>0.349007</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.466905</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.124689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.114442</td>\n",
       "      <td>0.078967</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.849732</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.824545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.120937</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.724508</td>\n",
       "      <td>0.424084</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.140890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.514763</td>\n",
       "      <td>0.111658</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.652952</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.110650</td>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.568873</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.237167</td>\n",
       "      <td>0.097627</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.483005</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "0        0.250               0.986507                   0.000000   \n",
       "1        0.875               0.617426                   0.000000   \n",
       "2        0.875               0.996708                   0.026042   \n",
       "3        0.625               0.475100                   0.031250   \n",
       "4        1.000               0.842307                   0.000000   \n",
       "...        ...                    ...                        ...   \n",
       "999995   0.875               0.124689                   0.000000   \n",
       "999996   1.000               0.824545                   0.000000   \n",
       "999997   0.875               0.140890                   0.000000   \n",
       "999998   1.000               0.002479                   0.138021   \n",
       "999999   0.625               0.993392                   0.000000   \n",
       "\n",
       "        customer_age  days_since_request  intended_balcon_amount  \\\n",
       "0              0.375            0.000086                0.918255   \n",
       "1              0.125            0.000129                0.114260   \n",
       "2              0.375            0.000157                0.109273   \n",
       "3              0.250            0.000089                0.106372   \n",
       "4              0.375            0.073195                0.487853   \n",
       "...              ...                 ...                     ...   \n",
       "999995         0.250            0.000654                0.114442   \n",
       "999996         0.250            0.000122                0.120937   \n",
       "999997         0.000            0.000756                0.514763   \n",
       "999998         0.250            0.000298                0.110650   \n",
       "999999         0.250            0.000260                0.237167   \n",
       "\n",
       "        zip_count_4w  date_of_birth_distinct_emails_4w  credit_risk_score  \\\n",
       "0           0.157934                          0.128205           0.595707   \n",
       "1           0.247350                          0.461538           0.579606   \n",
       "2           0.163308                          0.282051           0.463327   \n",
       "3           0.519779                          0.333333           0.465116   \n",
       "4           0.349007                          0.153846           0.466905   \n",
       "...              ...                               ...                ...   \n",
       "999995      0.078967                          0.205128           0.849732   \n",
       "999996      0.060755                          0.128205           0.724508   \n",
       "999997      0.111658                          0.076923           0.652952   \n",
       "999998      0.105389                          0.205128           0.568873   \n",
       "999999      0.097627                          0.205128           0.483005   \n",
       "\n",
       "        proposed_credit_limit  ...  has_other_cards_1  foreign_request_0  \\\n",
       "0                    0.685864  ...                0.0                1.0   \n",
       "1                    0.685864  ...                0.0                1.0   \n",
       "2                    0.005236  ...                0.0                1.0   \n",
       "3                    0.005236  ...                0.0                1.0   \n",
       "4                    0.005236  ...                0.0                1.0   \n",
       "...                       ...  ...                ...                ...   \n",
       "999995               0.685864  ...                0.0                1.0   \n",
       "999996               0.424084  ...                1.0                1.0   \n",
       "999997               0.005236  ...                0.0                1.0   \n",
       "999998               0.005236  ...                0.0                1.0   \n",
       "999999               0.005236  ...                1.0                1.0   \n",
       "\n",
       "        foreign_request_1  source_INTERNET  source_TELEAPP  device_os_linux  \\\n",
       "0                     0.0              1.0             0.0              1.0   \n",
       "1                     0.0              1.0             0.0              0.0   \n",
       "2                     0.0              1.0             0.0              0.0   \n",
       "3                     0.0              1.0             0.0              1.0   \n",
       "4                     0.0              1.0             0.0              0.0   \n",
       "...                   ...              ...             ...              ...   \n",
       "999995                0.0              1.0             0.0              0.0   \n",
       "999996                0.0              1.0             0.0              0.0   \n",
       "999997                0.0              1.0             0.0              0.0   \n",
       "999998                0.0              1.0             0.0              1.0   \n",
       "999999                0.0              1.0             0.0              0.0   \n",
       "\n",
       "        device_os_other  device_os_windows  keep_alive_session_1  month_3  \n",
       "0                   0.0                0.0                   1.0      0.0  \n",
       "1                   1.0                0.0                   1.0      0.0  \n",
       "2                   0.0                1.0                   0.0      0.0  \n",
       "3                   0.0                0.0                   1.0      0.0  \n",
       "4                   1.0                0.0                   0.0      0.0  \n",
       "...                 ...                ...                   ...      ...  \n",
       "999995              1.0                0.0                   0.0      0.0  \n",
       "999996              0.0                0.0                   0.0      0.0  \n",
       "999997              1.0                0.0                   0.0      0.0  \n",
       "999998              0.0                0.0                   1.0      0.0  \n",
       "999999              1.0                0.0                   1.0      0.0  \n",
       "\n",
       "[1000000 rows x 35 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e78ea0",
   "metadata": {},
   "source": [
    "#### LASSO with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0f75a52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:11\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#takes very very long to run\n",
    "#optimize a logistic function with a L1 penalty -> use logistic regression estimator with L1 penalty\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Create L1 regularized logistic regression\n",
    "l1_model = LogisticRegressionCV(penalty='l1', solver='liblinear', cv=5)\n",
    "l1_model.fit(X, y)\n",
    "\n",
    "# Get coefficients and feature names\n",
    "coef_l1 = l1_model.coef_[0]\n",
    "coef_df_l1 = pd.DataFrame({\n",
    "   'Feature': feature_names,\n",
    "   'Coefficient': coef_l1,\n",
    "})\n",
    "\n",
    "# Filter non-zero coefficients\n",
    "selected_features_l1 = coef_df_l1[coef_df_l1['Coefficient'] != 0]['Feature']\n",
    "\n",
    "print(\"Selected Features with L1 Regularization:\", selected_features_l1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424279be",
   "metadata": {},
   "source": [
    "#### Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def forward_selection_logistic(X, y, alpha=0.05):\n",
    "    selected_features = []\n",
    "    best_pvalue = 1\n",
    "\n",
    "    while True:\n",
    "        if len(selected_features) == len(X.columns):\n",
    "            break\n",
    "\n",
    "        candidate_features = [feature for feature in X.columns if feature not in selected_features]\n",
    "        pvalues = []\n",
    "\n",
    "        for feature in candidate_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            X_subset = sm.add_constant(X[current_features])\n",
    "            model = sm.Logit(y, X_subset).fit(disp=0)\n",
    "            pvalue = model.pvalues[feature]\n",
    "            pvalues.append((feature, pvalue))\n",
    "\n",
    "        best_candidate, best_candidate_pvalue = min(pvalues, key=lambda x: x[1])\n",
    "\n",
    "        if best_candidate_pvalue < alpha:\n",
    "            selected_features.append(best_candidate)\n",
    "            best_pvalue = best_candidate_pvalue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "# Assuming X is your feature DataFrame and y is the target Series or DataFrame\n",
    "selected_features_logistic = forward_selection_logistic(X, y)\n",
    "print(\"Selected Features using Logistic Regression and p-values:\", selected_features_logistic) #40\n",
    "#Selected Features using Logistic Regression and p-values: ['income', 'customer_age', 'credit_risk_score', 'device_distinct_emails_8w', \n",
    "# 'housing_status_BA', 'phone_home_valid_0', 'has_other_cards_0', 'device_os_windows', 'keep_alive_session_1', 'name_email_similarity', \n",
    "# 'email_is_free_1', 'payment_type_AC', 'prev_address_months_count', 'month_3', 'device_os_macintosh', 'employment_status_CB', \n",
    "# 'bank_months_count', 'month_4', 'proposed_credit_limit', 'date_of_birth_distinct_emails_4w', 'zip_count_4w', 'foreign_request_1', \n",
    "# 'intended_balcon_amount', 'employment_status_CF', 'phone_mobile_valid_0', 'month_7', 'device_os_linux', 'employment_status_CD', \n",
    "# 'employment_status_CE', 'days_since_request', 'source_TELEAPP', 'housing_status_BE', 'month_2', 'employment_status_CA', 'month_1',\n",
    "# 'velocity_24h', 'bank_branch_count_8w', 'device_os_other', 'housing_status_BD', 'payment_type_AA']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03d502ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_features_selected = ['income', 'customer_age', 'credit_risk_score', 'device_distinct_emails_8w', \n",
    "'housing_status_BA', 'phone_home_valid_0', 'has_other_cards_0', 'device_os_windows', 'keep_alive_session_1', 'name_email_similarity', \n",
    "'email_is_free_1', 'payment_type_AC', 'prev_address_months_count', 'month_3', 'device_os_macintosh', 'employment_status_CB', \n",
    "'bank_months_count', 'month_4', 'proposed_credit_limit', 'date_of_birth_distinct_emails_4w', 'zip_count_4w', 'foreign_request_1', \n",
    "'intended_balcon_amount', 'employment_status_CF', 'phone_mobile_valid_0', 'month_7', 'device_os_linux', 'employment_status_CD', \n",
    "'employment_status_CE', 'days_since_request', 'source_TELEAPP', 'housing_status_BE', 'month_2', 'employment_status_CA', 'month_1',\n",
    "'velocity_24h', 'bank_branch_count_8w', 'device_os_other', 'housing_status_BD', 'payment_type_AA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5633dfdf",
   "metadata": {},
   "source": [
    "#### Backward Stepwise Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4615fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteratively fits a Logistic Regression model & removes the feature with the highest p-value (least significant) in each iteration.\n",
    "#the process continues until the maximum p-value is less than the p_threshold, which is set to 0.05 by default.\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def backward_stepwise_selection(X, y, p_threshold=0.05):\n",
    "    features = X.columns.tolist()\n",
    "    num_features = len(features)\n",
    "    \n",
    "    for i in range(num_features, 0, -1):\n",
    "        model = sm.Logit(y, X[features]).fit()\n",
    "        p_values = model.pvalues\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value > p_threshold:\n",
    "            remove_feature = p_values.idxmax()\n",
    "            print(f\"Removing '{remove_feature}' with p-value: {max_p_value:.4f}\")\n",
    "            features.remove(remove_feature)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return features\n",
    "\n",
    "selected_features = backward_stepwise_selection(X, y)\n",
    "print(\"Selected Features:\", selected_features) #42\n",
    "# ['income', 'name_email_similarity', 'prev_address_months_count', 'customer_age', 'days_since_request', 'intended_balcon_amount', 'zip_count_4w', 'velocity_24h', \n",
    "# 'bank_branch_count_8w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score', 'bank_months_count', 'proposed_credit_limit', 'device_distinct_emails_8w', 'payment_type_AA', \n",
    "# 'payment_type_AB', 'payment_type_AD', 'employment_status_CA', 'employment_status_CC', 'employment_status_CE', 'employment_status_CF', 'email_is_free_0', 'housing_status_BA', \n",
    "# 'housing_status_BB', 'housing_status_BC', 'housing_status_BE', 'phone_home_valid_1', 'phone_mobile_valid_0', 'phone_mobile_valid_1', 'has_other_cards_0', 'foreign_request_1', \n",
    "# 'source_INTERNET', 'device_os_linux', 'device_os_macintosh', 'device_os_other', 'device_os_x11', 'keep_alive_session_1', 'month_1', 'month_2', 'month_3', 'month_4', 'month_7']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "965dfefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_features_selected = ['income', 'name_email_similarity', 'prev_address_months_count', 'customer_age', 'days_since_request', 'intended_balcon_amount', 'zip_count_4w', 'velocity_24h', \n",
    "'bank_branch_count_8w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score', 'bank_months_count', 'proposed_credit_limit', 'device_distinct_emails_8w', 'payment_type_AA', \n",
    "'payment_type_AB', 'payment_type_AD', 'employment_status_CA', 'employment_status_CC', 'employment_status_CE', 'employment_status_CF', 'email_is_free_0', 'housing_status_BA', \n",
    "'housing_status_BB', 'housing_status_BC', 'housing_status_BE', 'phone_home_valid_1', 'phone_mobile_valid_0', 'phone_mobile_valid_1', 'has_other_cards_0', 'foreign_request_1', \n",
    "'source_INTERNET', 'device_os_linux', 'device_os_macintosh', 'device_os_other', 'device_os_x11', 'keep_alive_session_1', 'month_1', 'month_2', 'month_3', 'month_4', 'month_7']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11391fd0",
   "metadata": {},
   "source": [
    "Chosen feature selection method: Backward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1f00652",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[backward_features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7848ccd3",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eddf8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=109) # 70% training and 30% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e4db2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76682201",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79578d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in y: 98.897%\n",
      "% of fraud class in y: 1.103%\n",
      "\n",
      "% of non-fraud class in y_train: 98.892%\n",
      "% of fraud class in y_train: 1.108%\n",
      "\n",
      "% of non-fraud class in y_test: 98.909%\n",
      "% of fraud class in y_test: 1.091%\n"
     ]
    }
   ],
   "source": [
    "ratio = y.fraud_bool.value_counts() / len(y) * 100\n",
    "print(f'% of non-fraud class in y: {round(ratio[0],3)}%\\n% of fraud class in y: {round(ratio[1],3)}%\\n')\n",
    "\n",
    "ratio_train = y_train.fraud_bool.value_counts() / len(y_train) * 100\n",
    "print(f'% of non-fraud class in y_train: {round(ratio_train[0],3)}%\\n% of fraud class in y_train: {round(ratio_train[1],3)}%\\n')\n",
    "\n",
    "ratio_test = y_test.fraud_bool.value_counts() / len(y_test) * 100\n",
    "print(f'% of non-fraud class in y_test: {round(ratio_test[0],3)}%\\n% of fraud class in y_test: {round(ratio_test[1],3)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49a9006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 42 columns):\n",
      " #   Column                            Non-Null Count    Dtype  \n",
      "---  ------                            --------------    -----  \n",
      " 0   income                            1000000 non-null  float64\n",
      " 1   name_email_similarity             1000000 non-null  float64\n",
      " 2   prev_address_months_count         1000000 non-null  float64\n",
      " 3   customer_age                      1000000 non-null  float64\n",
      " 4   days_since_request                1000000 non-null  float64\n",
      " 5   intended_balcon_amount            1000000 non-null  float64\n",
      " 6   zip_count_4w                      1000000 non-null  float64\n",
      " 7   velocity_24h                      1000000 non-null  float64\n",
      " 8   bank_branch_count_8w              1000000 non-null  float64\n",
      " 9   date_of_birth_distinct_emails_4w  1000000 non-null  float64\n",
      " 10  credit_risk_score                 1000000 non-null  float64\n",
      " 11  bank_months_count                 1000000 non-null  float64\n",
      " 12  proposed_credit_limit             1000000 non-null  float64\n",
      " 13  device_distinct_emails_8w         1000000 non-null  float64\n",
      " 14  payment_type_AA                   1000000 non-null  float64\n",
      " 15  payment_type_AB                   1000000 non-null  float64\n",
      " 16  payment_type_AD                   1000000 non-null  float64\n",
      " 17  employment_status_CA              1000000 non-null  float64\n",
      " 18  employment_status_CC              1000000 non-null  float64\n",
      " 19  employment_status_CE              1000000 non-null  float64\n",
      " 20  employment_status_CF              1000000 non-null  float64\n",
      " 21  email_is_free_0                   1000000 non-null  float64\n",
      " 22  housing_status_BA                 1000000 non-null  float64\n",
      " 23  housing_status_BB                 1000000 non-null  float64\n",
      " 24  housing_status_BC                 1000000 non-null  float64\n",
      " 25  housing_status_BE                 1000000 non-null  float64\n",
      " 26  phone_home_valid_1                1000000 non-null  float64\n",
      " 27  phone_mobile_valid_0              1000000 non-null  float64\n",
      " 28  phone_mobile_valid_1              1000000 non-null  float64\n",
      " 29  has_other_cards_0                 1000000 non-null  float64\n",
      " 30  foreign_request_1                 1000000 non-null  float64\n",
      " 31  source_INTERNET                   1000000 non-null  float64\n",
      " 32  device_os_linux                   1000000 non-null  float64\n",
      " 33  device_os_macintosh               1000000 non-null  float64\n",
      " 34  device_os_other                   1000000 non-null  float64\n",
      " 35  device_os_x11                     1000000 non-null  float64\n",
      " 36  keep_alive_session_1              1000000 non-null  float64\n",
      " 37  month_1                           1000000 non-null  float64\n",
      " 38  month_2                           1000000 non-null  float64\n",
      " 39  month_3                           1000000 non-null  float64\n",
      " 40  month_4                           1000000 non-null  float64\n",
      " 41  month_7                           1000000 non-null  float64\n",
      "dtypes: float64(42)\n",
      "memory usage: 320.4 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622df4d",
   "metadata": {},
   "source": [
    "### Individual Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170d4bc",
   "metadata": {},
   "source": [
    "#### Random Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe18a8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in resampled data: 97.832%\n",
      "% of fraud class in resampled data: 2.168%\n",
      "CPU times: total: 688 ms\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "desired_majority_size = int(0.5 * len(X_train))  # 50% of the original majority class size\n",
    "\n",
    "# Initialize RandomUnderSampler to undersample the majority class to 50%\n",
    "under_sampler = RandomUnderSampler(sampling_strategy={0: desired_majority_size}, random_state=42)\n",
    "\n",
    "# Apply RandomUnderSampler\n",
    "Xt_resampled_under, yt_resampled_under = under_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize SMOTE to oversample the minority class to match the majority class\n",
    "# smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# # Apply SMOTE on the undersampled data\n",
    "# Xt_resampled, yt_resampled = smote.fit_resample(Xt_resampled_under, yt_resampled_under)\n",
    "\n",
    "tmp = yt_resampled_under.fraud_bool.value_counts() / len(yt_resampled_under) * 100\n",
    "print(f'% of non-fraud class in resampled data: {round(tmp[0],3)}%\\n% of fraud class in resampled data: {round(tmp[1],3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe3828",
   "metadata": {},
   "source": [
    "#### Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4372d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in resampled data: 98.887%\n",
      "% of fraud class in resampled data: 1.113%\n",
      "CPU times: total: 58min 39s\n",
      "Wall time: 20min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "tl = TomekLinks()\n",
    "Xt_resampled_tl, yt_resampled_tl = tl.fit_resample(X_train, y_train)\n",
    "\n",
    "ratio_tl = yt_resampled_tl.fraud_bool.value_counts() / len(yt_resampled_tl) * 100\n",
    "print(f'% of non-fraud class in resampled data: {round(ratio_tl[0],3)}%\\n% of fraud class in resampled data: {round(ratio_tl[1],3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e77e4",
   "metadata": {},
   "source": [
    "#### Cluster Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4cd4f",
   "metadata": {},
   "source": [
    "can tune estimator -- default is KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a1b430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from imblearn.under_sampling import ClusterCentroids\n",
    "# cc = ClusterCentroids(random_state = 42)\n",
    "# Xt_resampled_cc, yt_resampled_cc = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "# ratio_cc = yt_resampled_cc.fraud_bool.value_counts() / len(yt_resampled_cc) * 100\n",
    "# print(f'% of non-fraud class in resampled data: {round(ratio_cc[0],3)}%\\n% of fraud class in resampled data: {round(ratio_cc[1],3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340eeb6",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78071219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in resampled data: 60.024%\n",
      "% of fraud class in resampled data: 39.976%\n",
      "CPU times: total: 2.34 s\n",
      "Wall time: 3.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42, sampling_strategy = 0.666) #ratio of minority:majority 40:60\n",
    "\n",
    "Xt_resampled_SMOTE, yt_resampled_SMOTE = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "ratio_SMOTE = yt_resampled_SMOTE.fraud_bool.value_counts() / len(yt_resampled_SMOTE) * 100\n",
    "print(f'% of non-fraud class in resampled data: {round(ratio_SMOTE[0],3)}%\\n% of fraud class in resampled data: {round(ratio_SMOTE[1],3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94459dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['income', 'name_email_similarity', 'prev_address_months_count',\n",
       "       'customer_age', 'days_since_request', 'intended_balcon_amount',\n",
       "       'zip_count_4w', 'velocity_24h', 'bank_branch_count_8w',\n",
       "       'date_of_birth_distinct_emails_4w', 'credit_risk_score',\n",
       "       'bank_months_count', 'proposed_credit_limit',\n",
       "       'device_distinct_emails_8w', 'payment_type_AA', 'payment_type_AB',\n",
       "       'payment_type_AD', 'employment_status_CA', 'employment_status_CC',\n",
       "       'employment_status_CE', 'employment_status_CF', 'email_is_free_0',\n",
       "       'housing_status_BA', 'housing_status_BB', 'housing_status_BC',\n",
       "       'housing_status_BE', 'phone_home_valid_1', 'phone_mobile_valid_0',\n",
       "       'phone_mobile_valid_1', 'has_other_cards_0', 'foreign_request_1',\n",
       "       'source_INTERNET', 'device_os_linux', 'device_os_macintosh',\n",
       "       'device_os_other', 'device_os_x11', 'keep_alive_session_1', 'month_1',\n",
       "       'month_2', 'month_3', 'month_4', 'month_7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc979b9",
   "metadata": {},
   "source": [
    "#### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43218044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of non-fraud class in resampled data: 59.941%\n",
      "% of fraud class in resampled data: 40.059%\n",
      "CPU times: total: 36.5 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN(random_state=42, sampling_strategy = 0.666)\n",
    "Xt_resampled_adasyn, yt_resampled_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "ratio_adasyn = yt_resampled_adasyn.fraud_bool.value_counts() / len(yt_resampled_adasyn) * 100\n",
    "print(f'% of non-fraud class in resampled data: {round(ratio_adasyn[0],3)}%\\n% of fraud class in resampled data: {round(ratio_adasyn[1],3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea2872",
   "metadata": {},
   "source": [
    "#### Evaluate Individual Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110e5a1",
   "metadata": {},
   "source": [
    "evaluation metrics to use:\n",
    "1. precision\n",
    "2. recall\n",
    "3. F2, F1.5, F1\n",
    "3. TPR, FNR\n",
    "4. PR-AUC\n",
    "\n",
    "https://sinyi-chou.github.io/python-sklearn-precision-recall/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c45a215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}\n",
    "f2_scores = {}\n",
    "f15_scores = {}\n",
    "f1_scores = {}\n",
    "recall_scores = {}\n",
    "precision_scores = {}\n",
    "class_reports = {}\n",
    "pr_auc = {}\n",
    "pr_auc_pts = {}\n",
    "tpr = {}\n",
    "fnr = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68617fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "logistic = LogisticRegression(random_state=42)\n",
    "# svm = SVC(kernel='linear', random_state=42)\n",
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5aecf387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, fbeta_score, f1_score, average_precision_score, precision_recall_curve, confusion_matrix\n",
    "def evaluate_results(model,resampler,x_resampled, y_resampled):\n",
    "\n",
    "    model.fit(x_resampled, y_resampled)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    accuracies[resampler] = accuracy_score(y_test, y_pred_test)\n",
    "    class_reports[resampler] = classification_report(y_test, y_pred_test)\n",
    "    recall_scores[resampler] = recall_score(y_test, y_pred_test)\n",
    "    precision_scores[resampler] = precision_score(y_test, y_pred_test)\n",
    "    f2_scores[resampler] = fbeta_score(y_test, y_pred_test, beta =2)\n",
    "    f15_scores[resampler] = fbeta_score(y_test, y_pred_test, beta =1.5)\n",
    "    f1_scores[resampler] = f1_score(y_test, y_pred_test)\n",
    "    pr_auc[resampler] = average_precision_score(y_test, y_pred_test)\n",
    "    pr_auc_pts[resampler] = precision_recall_curve(y_test, y_pred_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred_test, labels=[0,1])\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    # TP = np.diag(cm).astype(float)\n",
    "    # FN = (cm.sum(axis=1) -np.diag(cm)).astype(float)\n",
    "    TPR = TP/(TP+FN)\n",
    "    FNR = FN/(TP+FN)\n",
    "    tpr[resampler] = TPR\n",
    "    fnr[resampler] = FNR\n",
    "    # print(cm)\n",
    "    # print(TP,FN)\n",
    "    # print(TPR, FNR)\n",
    "\n",
    "    print(f\"{resampler} Model Performance on Test Data:\")\n",
    "    print(f\"{resampler} Accuracy:\", accuracies[resampler])\n",
    "    print(f\"{resampler} Precision: {precision_scores[resampler]}\")\n",
    "    print(f\"{resampler} Recall: {recall_scores[resampler]}\")\n",
    "    print(f\"{resampler} F2: {f2_scores[resampler]}\")\n",
    "    print(f\"{resampler} F1.5: {f15_scores[resampler]}\")\n",
    "    print(f\"{resampler} F1: {f1_scores[resampler]}\")\n",
    "    print(f\"{resampler} PR-AUC: {pr_auc[resampler]}\")\n",
    "    print(f\"{resampler} Classification Report: \\n{class_reports[resampler]}\")\n",
    "    # print(classification_report(y_test, y_pred_test),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34a6fc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Model Performance on Test Data:\n",
      "Original Dataset Accuracy: 0.9890933333333334\n",
      "Original Dataset Precision: 0.5178571428571429\n",
      "Original Dataset Recall: 0.00885766646304215\n",
      "Original Dataset F2: 0.011024939172749392\n",
      "Original Dataset F1.5: 0.012697878073425395\n",
      "Original Dataset F1: 0.017417417417417418\n",
      "Original Dataset PR-AUC: 0.015403672513599208\n",
      "Original Dataset Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.52      0.01      0.02      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.75      0.50      0.51    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample Model Performance on Test Data:\n",
      "Random Undersample Accuracy: 0.9889366666666667\n",
      "Random Undersample Precision: 0.43034055727554177\n",
      "Random Undersample Recall: 0.04245571166768479\n",
      "Random Undersample F2: 0.05179223489082644\n",
      "Random Undersample F1.5: 0.05874894336432798\n",
      "Random Undersample F1: 0.07728662774534334\n",
      "Random Undersample PR-AUC: 0.028720414618601194\n",
      "Random Undersample Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.43      0.04      0.08      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.71      0.52      0.54    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links Model Performance on Test Data:\n",
      "Tomek Links Accuracy: 0.9890833333333333\n",
      "Tomek Links Precision: 0.4931506849315068\n",
      "Tomek Links Recall: 0.010995723885155772\n",
      "Tomek Links F2: 0.01366846381653884\n",
      "Tomek Links F1.5: 0.015726863364473417\n",
      "Tomek Links F1: 0.02151180161338512\n",
      "Tomek Links PR-AUC: 0.01621588209861563\n",
      "Tomek Links Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.49      0.01      0.02      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.74      0.51      0.51    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE Model Performance on Test Data:\n",
      "SMOTE Accuracy: 0.86589\n",
      "SMOTE Precision: 0.05562101719369965\n",
      "SMOTE Recall: 0.7064752596212583\n",
      "SMOTE F2: 0.21149942393153015\n",
      "SMOTE F1.5: 0.15356526357721417\n",
      "SMOTE F1: 0.10312311910653381\n",
      "SMOTE PR-AUC: 0.042498205895650766\n",
      "SMOTE Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.87    300000\n",
      "   macro avg       0.53      0.79      0.52    300000\n",
      "weighted avg       0.99      0.87      0.92    300000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN Model Performance on Test Data:\n",
      "ADASYN Accuracy: 0.86133\n",
      "ADASYN Precision: 0.05428538202116525\n",
      "ADASYN Recall: 0.7128894318875992\n",
      "ADASYN F2: 0.20805476814462212\n",
      "ADASYN F1.5: 0.1506210100969987\n",
      "ADASYN F1: 0.10088828373208844\n",
      "ADASYN PR-AUC: 0.041832808482203124\n",
      "ADASYN Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.92    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_results(logistic,\"Original Dataset\",X_train, y_train)\n",
    "evaluate_results(logistic,\"Random Undersample\",Xt_resampled_under, yt_resampled_under)\n",
    "evaluate_results(logistic,\"Tomek Links\",Xt_resampled_tl, yt_resampled_tl)\n",
    "#evaluate_results(logistic,\"Cluster Centroid\",Xt_resampled_cc, yt_resampled_cc)\n",
    "evaluate_results(logistic,\"SMOTE\",Xt_resampled_SMOTE, yt_resampled_SMOTE)\n",
    "evaluate_results(logistic,\"ADASYN\",Xt_resampled_adasyn, yt_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "699307d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_results(svm,\"Random Undersample\",Xt_resampled_under, yt_resampled_under)\n",
    "#evaluate_results(svm,\"Tomek Links\",Xt_resampled_tl, yt_resampled_tl)\n",
    "#evaluate_results(svm,\"Cluster Centroid\",Xt_resampled_cc, yt_resampled_cc)\n",
    "#evaluate_results(svm,\"SMOTE\",Xt_resampled_SMOTE, yt_resampled_SMOTE)\n",
    "#evaluate_results(svm,\"ADASYN\",Xt_resampled_adasyn, yt_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b2158e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_results(rf_classifier,\"Random Undersample\",Xt_resampled_under, yt_resampled_under)\n",
    "# evaluate_results(rf_classifier,\"Tomek Links\",Xt_resampled_tl, yt_resampled_tl)\n",
    "# #evaluate_results(rf,\"Cluster Centroid\",Xt_resampled_cc, yt_resampled_cc)\n",
    "# evaluate_results(rf_classifier,\"SMOTE\",Xt_resampled_SMOTE, yt_resampled_SMOTE)\n",
    "# evaluate_results(rf_classifier,\"ADASYN\",Xt_resampled_adasyn, yt_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16f10a",
   "metadata": {},
   "source": [
    "### Combined Undersample + Oversample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae311f5",
   "metadata": {},
   "source": [
    "#### Undersampling methods + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46d2ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_smote(undersampler, X_undersampled, y_undersampled):\n",
    "    smote = SMOTE(random_state=42, sampling_strategy = 0.666)\n",
    "\n",
    "    # Apply SMOTE on the undersampled data\n",
    "    Xt_resampled, yt_resampled = smote.fit_resample(X_undersampled, y_undersampled)\n",
    "\n",
    "    tmp = yt_resampled.fraud_bool.value_counts() / len(yt_resampled) * 100\n",
    "    print(f'{undersampler}:\\n% of non-fraud class in resampled data: {round(tmp[0],3)}%\\n% of fraud class in resampled data: {round(tmp[1],3)}%')\n",
    "    \n",
    "    evaluate_results(logistic, undersampler+' + SMOTE',Xt_resampled, yt_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60f95184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample:\n",
      "% of non-fraud class in resampled data: 60.024%\n",
      "% of fraud class in resampled data: 39.976%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample + SMOTE Model Performance on Test Data:\n",
      "Random Undersample + SMOTE Accuracy: 0.8659933333333333\n",
      "Random Undersample + SMOTE Precision: 0.05566251143090918\n",
      "Random Undersample + SMOTE Recall: 0.7064752596212583\n",
      "Random Undersample + SMOTE F2: 0.21161939615736505\n",
      "Random Undersample + SMOTE F1.5: 0.1536625749941231\n",
      "Random Undersample + SMOTE F1: 0.10319443205139645\n",
      "Random Undersample + SMOTE PR-AUC: 0.04252752054765616\n",
      "Random Undersample + SMOTE Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.87    300000\n",
      "   macro avg       0.53      0.79      0.52    300000\n",
      "weighted avg       0.99      0.87      0.92    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undersample_smote('Random Undersample',Xt_resampled_under, yt_resampled_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9be01f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links:\n",
      "% of non-fraud class in resampled data: 60.024%\n",
      "% of fraud class in resampled data: 39.976%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links + SMOTE Model Performance on Test Data:\n",
      "Tomek Links + SMOTE Accuracy: 0.8649\n",
      "Tomek Links + SMOTE Precision: 0.05535398863799112\n",
      "Tomek Links + SMOTE Recall: 0.7083078802687843\n",
      "Tomek Links + SMOTE F2: 0.21085651936715766\n",
      "Tomek Links + SMOTE F1.5: 0.15299783802438058\n",
      "Tomek Links + SMOTE F1: 0.10268331562167907\n",
      "Tomek Links + SMOTE PR-AUC: 0.042390999689931194\n",
      "Tomek Links + SMOTE Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.92    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undersample_smote('Tomek Links', Xt_resampled_tl, yt_resampled_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b8531a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersample_smote('Cluster Centroid', Xt_resampled_cc, yt_resampled_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ad243",
   "metadata": {},
   "source": [
    "#### Undersampling methods + ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d0ad409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_adasyn(undersampler, X_undersampled, y_undersampled):\n",
    "    adasyn = ADASYN(random_state=42, sampling_strategy = 0.666)\n",
    "\n",
    "    # Apply SMOTE on the undersampled data\n",
    "    Xt_resampled, yt_resampled = adasyn.fit_resample(X_undersampled, y_undersampled)\n",
    "\n",
    "    tmp = yt_resampled.fraud_bool.value_counts() / len(yt_resampled) * 100\n",
    "    print(f'{undersampler}:\\n% of non-fraud class in resampled data: {round(tmp[0],3)}%\\n% of fraud class in resampled data: {round(tmp[1],3)}%')\n",
    "    \n",
    "    evaluate_results(logistic, undersampler+' + ADASYN',Xt_resampled, yt_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04e354c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample:\n",
      "% of non-fraud class in resampled data: 59.978%\n",
      "% of fraud class in resampled data: 40.022%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Undersample + ADASYN Model Performance on Test Data:\n",
      "Random Undersample + ADASYN Accuracy: 0.8586433333333333\n",
      "Random Undersample + ADASYN Precision: 0.05359220642923958\n",
      "Random Undersample + ADASYN Recall: 0.7174709835064141\n",
      "Random Undersample + ADASYN F2: 0.20631686194600102\n",
      "Random Undersample + ADASYN F1.5: 0.14911372625616484\n",
      "Random Undersample + ADASYN F1: 0.09973463538902452\n",
      "Random Undersample + ADASYN PR-AUC: 0.041534186388398626\n",
      "Random Undersample + ADASYN Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.72      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.52      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.91    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undersample_adasyn('Random Undersample',Xt_resampled_under, yt_resampled_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd98d9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links:\n",
      "% of non-fraud class in resampled data: 60.097%\n",
      "% of fraud class in resampled data: 39.903%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomek Links + ADASYN Model Performance on Test Data:\n",
      "Tomek Links + ADASYN Accuracy: 0.8603133333333334\n",
      "Tomek Links + ADASYN Precision: 0.05402659770964167\n",
      "Tomek Links + ADASYN Recall: 0.7147220525351252\n",
      "Tomek Links + ADASYN F2: 0.2074173876045951\n",
      "Tomek Links + ADASYN F1.5: 0.15006363645332835\n",
      "Tomek Links + ADASYN F1: 0.1004593654746061\n",
      "Tomek Links + ADASYN PR-AUC: 0.04172733413985792\n",
      "Tomek Links + ADASYN Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.92    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "undersample_adasyn('Tomek Links',Xt_resampled_tl, yt_resampled_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4658a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample_adasyn('Cluster Centroid',Xt_resampled_cc, yt_resampled_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3de7ad",
   "metadata": {},
   "source": [
    "### All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25565bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Dataset</th>\n",
       "      <th>Random Undersample</th>\n",
       "      <th>Tomek Links</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>ADASYN</th>\n",
       "      <th>Random Undersample + SMOTE</th>\n",
       "      <th>Tomek Links + SMOTE</th>\n",
       "      <th>Random Undersample + ADASYN</th>\n",
       "      <th>Tomek Links + ADASYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.989093</td>\n",
       "      <td>0.988937</td>\n",
       "      <td>0.989083</td>\n",
       "      <td>0.86589</td>\n",
       "      <td>0.86133</td>\n",
       "      <td>0.865993</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>0.858643</td>\n",
       "      <td>0.860313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.008858</td>\n",
       "      <td>0.042456</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.706475</td>\n",
       "      <td>0.712889</td>\n",
       "      <td>0.706475</td>\n",
       "      <td>0.708308</td>\n",
       "      <td>0.717471</td>\n",
       "      <td>0.714722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.430341</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.055621</td>\n",
       "      <td>0.054285</td>\n",
       "      <td>0.055663</td>\n",
       "      <td>0.055354</td>\n",
       "      <td>0.053592</td>\n",
       "      <td>0.054027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2 Score</th>\n",
       "      <td>0.011025</td>\n",
       "      <td>0.051792</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>0.211499</td>\n",
       "      <td>0.208055</td>\n",
       "      <td>0.211619</td>\n",
       "      <td>0.210857</td>\n",
       "      <td>0.206317</td>\n",
       "      <td>0.207417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1.5 Score</th>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.058749</td>\n",
       "      <td>0.015727</td>\n",
       "      <td>0.153565</td>\n",
       "      <td>0.150621</td>\n",
       "      <td>0.153663</td>\n",
       "      <td>0.152998</td>\n",
       "      <td>0.149114</td>\n",
       "      <td>0.150064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.017417</td>\n",
       "      <td>0.077287</td>\n",
       "      <td>0.021512</td>\n",
       "      <td>0.103123</td>\n",
       "      <td>0.100888</td>\n",
       "      <td>0.103194</td>\n",
       "      <td>0.102683</td>\n",
       "      <td>0.099735</td>\n",
       "      <td>0.100459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.008858</td>\n",
       "      <td>0.042456</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.706475</td>\n",
       "      <td>0.712889</td>\n",
       "      <td>0.706475</td>\n",
       "      <td>0.708308</td>\n",
       "      <td>0.717471</td>\n",
       "      <td>0.714722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNR</th>\n",
       "      <td>0.991142</td>\n",
       "      <td>0.957544</td>\n",
       "      <td>0.989004</td>\n",
       "      <td>0.293525</td>\n",
       "      <td>0.287111</td>\n",
       "      <td>0.293525</td>\n",
       "      <td>0.291692</td>\n",
       "      <td>0.282529</td>\n",
       "      <td>0.285278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR-AUC</th>\n",
       "      <td>0.015404</td>\n",
       "      <td>0.02872</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.042498</td>\n",
       "      <td>0.041833</td>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.042391</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.041727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Original Dataset Random Undersample Tomek Links     SMOTE  \\\n",
       "Accuracy           0.989093           0.988937    0.989083   0.86589   \n",
       "Recall             0.008858           0.042456    0.010996  0.706475   \n",
       "Precision          0.517857           0.430341    0.493151  0.055621   \n",
       "F2 Score           0.011025           0.051792    0.013668  0.211499   \n",
       "F1.5 Score         0.012698           0.058749    0.015727  0.153565   \n",
       "F1 Score           0.017417           0.077287    0.021512  0.103123   \n",
       "TPR                0.008858           0.042456    0.010996  0.706475   \n",
       "FNR                0.991142           0.957544    0.989004  0.293525   \n",
       "PR-AUC             0.015404            0.02872    0.016216  0.042498   \n",
       "\n",
       "              ADASYN Random Undersample + SMOTE Tomek Links + SMOTE  \\\n",
       "Accuracy     0.86133                   0.865993              0.8649   \n",
       "Recall      0.712889                   0.706475            0.708308   \n",
       "Precision   0.054285                   0.055663            0.055354   \n",
       "F2 Score    0.208055                   0.211619            0.210857   \n",
       "F1.5 Score  0.150621                   0.153663            0.152998   \n",
       "F1 Score    0.100888                   0.103194            0.102683   \n",
       "TPR         0.712889                   0.706475            0.708308   \n",
       "FNR         0.287111                   0.293525            0.291692   \n",
       "PR-AUC      0.041833                   0.042528            0.042391   \n",
       "\n",
       "           Random Undersample + ADASYN Tomek Links + ADASYN  \n",
       "Accuracy                      0.858643             0.860313  \n",
       "Recall                        0.717471             0.714722  \n",
       "Precision                     0.053592             0.054027  \n",
       "F2 Score                      0.206317             0.207417  \n",
       "F1.5 Score                    0.149114             0.150064  \n",
       "F1 Score                      0.099735             0.100459  \n",
       "TPR                           0.717471             0.714722  \n",
       "FNR                           0.282529             0.285278  \n",
       "PR-AUC                        0.041534             0.041727  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_names = ['Accuracy', 'Recall','Precision', 'F2 Score', 'F1.5 Score','F1 Score', 'TPR','FNR', \"PR-AUC\"]\n",
    "results = pd.DataFrame(index= metrics_names,columns=accuracies.keys())\n",
    "all_results_list = [accuracies, recall_scores, precision_scores, f2_scores,f15_scores,f1_scores, tpr, fnr, pr_auc]\n",
    "for i in range(len(all_results_list)):\n",
    "    for k,v in all_results_list[i].items():\n",
    "        results.loc[metrics_names[i], str(k)] = v\n",
    "        \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92700102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.52      0.01      0.02      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.75      0.50      0.51    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      " \n",
      "\n",
      "Random Undersample :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.43      0.04      0.08      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.71      0.52      0.54    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      " \n",
      "\n",
      "Tomek Links :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    296726\n",
      "           1       0.49      0.01      0.02      3274\n",
      "\n",
      "    accuracy                           0.99    300000\n",
      "   macro avg       0.74      0.51      0.51    300000\n",
      "weighted avg       0.98      0.99      0.98    300000\n",
      " \n",
      "\n",
      "SMOTE :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.87    300000\n",
      "   macro avg       0.53      0.79      0.52    300000\n",
      "weighted avg       0.99      0.87      0.92    300000\n",
      " \n",
      "\n",
      "ADASYN :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.92    300000\n",
      " \n",
      "\n",
      "Random Undersample + SMOTE :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.87    300000\n",
      "   macro avg       0.53      0.79      0.52    300000\n",
      "weighted avg       0.99      0.87      0.92    300000\n",
      " \n",
      "\n",
      "Tomek Links + SMOTE :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    296726\n",
      "           1       0.06      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.92    300000\n",
      " \n",
      "\n",
      "Random Undersample + ADASYN :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.72      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.52      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.91    300000\n",
      " \n",
      "\n",
      "Tomek Links + ADASYN :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92    296726\n",
      "           1       0.05      0.71      0.10      3274\n",
      "\n",
      "    accuracy                           0.86    300000\n",
      "   macro avg       0.53      0.79      0.51    300000\n",
      "weighted avg       0.99      0.86      0.92    300000\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in class_reports.items():\n",
    "    print(k,':\\n', v,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29ff98dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "# iterate over the function list and add a subplot for each function\n",
    "for idx, x in enumerate(pr_auc_pts.items(), start=1):  \n",
    "    resampler = x[0]\n",
    "    v = x[1]\n",
    "    ax = fig.add_subplot(3, 3, idx) # plot with 2 rows and 3 columns\n",
    "    ax.plot(v[0],v[1])\n",
    "    ax.set_title(resampler)\n",
    "    ax.set_ylabel('Recall')\n",
    "    ax.set_xlabel('Precision')\n",
    "    \n",
    "\n",
    "# add spacing between subplots\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
